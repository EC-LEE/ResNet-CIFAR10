{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "h9m0AV7uGnJy"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1xtq78CcGpuM",
    "outputId": "e08bdcfe-97fe-4750-977c-37d5d9165b27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# transform = transforms.Compose(\n",
    "#     [transforms.ToTensor()])\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, valset = torch.utils.data.random_split(trainset, [45000, 5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "12KzKwOOHCBM"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, n):\n",
    "        super().__init__()\n",
    "        self.n = n\n",
    "        \n",
    "        self.conv = nn.Sequential(nn.Conv2d(3, 16, (3,3), padding=1),\\\n",
    "                    nn.BatchNorm2d(16))\n",
    "    \n",
    "        self.stage1 = nn.ModuleList()\n",
    "        for _ in range(n):\n",
    "                tmp = []\n",
    "                tmp.append(nn.Conv2d(16, 16, (3,3), padding=1))\n",
    "                tmp.append(nn.BatchNorm2d(16))\n",
    "                tmp.append(nn.ReLU())\n",
    "                tmp.append(nn.Conv2d(16, 16, (3,3), padding=1))\n",
    "                tmp.append(nn.BatchNorm2d(16))\n",
    "                self.stage1.append(nn.Sequential(*tmp))\n",
    "        \n",
    "        self.stage2 = nn.ModuleList()\n",
    "        for _ in range(n):\n",
    "                tmp = []\n",
    "                if _ == 0:\n",
    "                    tmp.append(nn.Conv2d(16, 32, (3,3), stride=2, padding=1))\n",
    "                else:\n",
    "                    tmp.append(nn.Conv2d(32, 32, (3,3), padding=1))\n",
    "                tmp.append(nn.BatchNorm2d(32))\n",
    "                tmp.append(nn.ReLU())\n",
    "                tmp.append(nn.Conv2d(32, 32, (3,3), padding=1))\n",
    "                tmp.append(nn.BatchNorm2d(32))\n",
    "                self.stage2.append(nn.Sequential(*tmp))\n",
    "        \n",
    "        self.stage3 = nn.ModuleList()\n",
    "        for _ in range(n):\n",
    "                tmp = []\n",
    "                if _ == 0:\n",
    "                    tmp.append(nn.Conv2d(32, 64, (3,3), stride=2, padding=1))\n",
    "                else:\n",
    "                    tmp.append(nn.Conv2d(64, 64, (3,3), padding=1))\n",
    "                tmp.append(nn.BatchNorm2d(64))\n",
    "                tmp.append(nn.ReLU())\n",
    "                tmp.append(nn.Conv2d(64, 64, (3,3), padding=1))\n",
    "                tmp.append(nn.BatchNorm2d(64))\n",
    "                self.stage3.append(nn.Sequential(*tmp))\n",
    "        \n",
    "        self.GAP = nn.AvgPool2d((8, 8))\n",
    "        self.fc = nn.Linear(64, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv(x))\n",
    "        ###stage_1\n",
    "        for i in range(self.n):\n",
    "            x = F.relu(self.stage1[i](x) + x)\n",
    "        ###stage_2    \n",
    "        for i in range(self.n):\n",
    "            if i == 0:\n",
    "                x_i = F.interpolate(x, size=x.shape[3]//2)  #size down\n",
    "                x_i = torch.cat((x_i,torch.zeros(x_i.shape).to(x.device)),1) #double channel\n",
    "                x = F.relu(self.stage2[i](x) + x_i)\n",
    "            else:\n",
    "                x = F.relu(self.stage2[i](x) + x)\n",
    "        ###stage_3\n",
    "        for i in range(self.n):\n",
    "            if i == 0:\n",
    "                x_i = F.interpolate(x, size=x.shape[3]//2) #size down\n",
    "                x_i = torch.cat((x_i, torch.zeros(x_i.shape).to(x.device)), 1) #double channel\n",
    "                x = F.relu(self.stage3[i](x) + x_i)\n",
    "            else:\n",
    "                x = F.relu(self.stage3[i](x) + x)\n",
    "        x = self.GAP(x) \n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "#weight Initialization\n",
    "def init_weights(m):\n",
    "        if type(m) == nn.Linear:\n",
    "            torch.nn.init.kaiming_normal_(m.weight)\n",
    "            m.bias.data.fill_(0.01)\n",
    "        \n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            torch.nn.init.kaiming_normal_(m.weight.data)\n",
    "            torch.nn.init.zeros_(m.bias.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet 32 \n",
    "N = 5\n",
    "\n",
    "net = Net(N);\n",
    "net.apply(init_weights);\n",
    "net.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1, weight_decay = 0.0001, momentum=0.9)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=4)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=4)\n",
    "print(len(trainloader))\n",
    "\n",
    "start_iter = 0\n",
    "end_iter = 64000\n",
    "it = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "1dlAatxDKdM-",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 100 , loss/100it: 2.776061017513275\n",
      "iter: 200 , loss/100it: 2.2238227486610413\n",
      "iter: 300 , loss/100it: 2.0731608951091767\n",
      "iter: 400 , loss/100it: 1.8699504792690278\n",
      "iter: 500 , loss/100it: 1.7405461978912353\n",
      "iter: 600 , loss/100it: 1.625420045852661\n",
      "iter: 700 , loss/100it: 1.5293361568450927\n",
      "iter: 800 , loss/100it: 1.4328518640995025\n",
      "iter: 900 , loss/100it: 1.3345908391475678\n",
      "iter: 1000 , loss/100it: 1.242227029800415\n",
      "iter: 1000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 49 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 49 %\n",
      "iter: 1100 , loss/100it: 1.1905099976062774\n",
      "iter: 1200 , loss/100it: 1.1350100088119506\n",
      "iter: 1300 , loss/100it: 1.0865227764844894\n",
      "iter: 1400 , loss/100it: 1.040309603214264\n",
      "iter: 1500 , loss/100it: 1.006677429676056\n",
      "iter: 1600 , loss/100it: 0.947714912891388\n",
      "iter: 1700 , loss/100it: 0.9185647308826447\n",
      "iter: 1800 , loss/100it: 0.8659544199705124\n",
      "iter: 1900 , loss/100it: 0.8461891549825669\n",
      "iter: 2000 , loss/100it: 0.8155267602205276\n",
      "iter: 2000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 67 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 66 %\n",
      "iter: 2100 , loss/100it: 0.8257236659526825\n",
      "iter: 2200 , loss/100it: 0.7683386778831482\n",
      "iter: 2300 , loss/100it: 0.7486011356115341\n",
      "iter: 2400 , loss/100it: 0.736966110765934\n",
      "iter: 2500 , loss/100it: 0.7375249874591827\n",
      "iter: 2600 , loss/100it: 0.6927392381429672\n",
      "iter: 2700 , loss/100it: 0.6886594778299332\n",
      "iter: 2800 , loss/100it: 0.6688291102647781\n",
      "iter: 2900 , loss/100it: 0.6432885944843292\n",
      "iter: 3000 , loss/100it: 0.6436779075860977\n",
      "iter: 3000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 77 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 76 %\n",
      "iter: 3100 , loss/100it: 0.6360220634937286\n",
      "iter: 3200 , loss/100it: 0.6148024424910545\n",
      "iter: 3300 , loss/100it: 0.5959998366236686\n",
      "iter: 3400 , loss/100it: 0.609225625693798\n",
      "iter: 3500 , loss/100it: 0.584086394906044\n",
      "iter: 3600 , loss/100it: 0.567904791533947\n",
      "iter: 3700 , loss/100it: 0.5606162542104721\n",
      "iter: 3800 , loss/100it: 0.5688399934768676\n",
      "iter: 3900 , loss/100it: 0.5628881266713143\n",
      "iter: 4000 , loss/100it: 0.5385705006122589\n",
      "iter: 4000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 77 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 75 %\n",
      "iter: 4100 , loss/100it: 0.5287189266085625\n",
      "iter: 4200 , loss/100it: 0.5371644803881646\n",
      "iter: 4300 , loss/100it: 0.5148895570635795\n",
      "iter: 4400 , loss/100it: 0.49692031741142273\n",
      "iter: 4500 , loss/100it: 0.5074835246801377\n",
      "iter: 4600 , loss/100it: 0.5040699172019959\n",
      "iter: 4700 , loss/100it: 0.5031294313073158\n",
      "iter: 4800 , loss/100it: 0.4814636567234993\n",
      "iter: 4900 , loss/100it: 0.48636101752519606\n",
      "iter: 5000 , loss/100it: 0.48802603274583817\n",
      "iter: 5000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 80 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 78 %\n",
      "iter: 5100 , loss/100it: 0.47686625242233277\n",
      "iter: 5200 , loss/100it: 0.45834880858659743\n",
      "iter: 5300 , loss/100it: 0.46867247223854064\n",
      "iter: 5400 , loss/100it: 0.45468522012233736\n",
      "iter: 5500 , loss/100it: 0.4876430633664131\n",
      "iter: 5600 , loss/100it: 0.45151347219944\n",
      "iter: 5700 , loss/100it: 0.4279934924840927\n",
      "iter: 5800 , loss/100it: 0.43218362122774123\n",
      "iter: 5900 , loss/100it: 0.4512398758530617\n",
      "iter: 6000 , loss/100it: 0.4386091038584709\n",
      "iter: 6000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 86 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 83 %\n",
      "iter: 6100 , loss/100it: 0.3913523402810097\n",
      "iter: 6200 , loss/100it: 0.42510572612285613\n",
      "iter: 6300 , loss/100it: 0.4433697661757469\n",
      "iter: 6400 , loss/100it: 0.42438491970300674\n",
      "iter: 6500 , loss/100it: 0.40662332355976105\n",
      "iter: 6600 , loss/100it: 0.4041089987754822\n",
      "iter: 6700 , loss/100it: 0.4160527646541595\n",
      "iter: 6800 , loss/100it: 0.39399429395794866\n",
      "iter: 6900 , loss/100it: 0.3948985515534878\n",
      "iter: 7000 , loss/100it: 0.41107780665159227\n",
      "iter: 7000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 84 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 80 %\n",
      "iter: 7100 , loss/100it: 0.39473218947649\n",
      "iter: 7200 , loss/100it: 0.392297403216362\n",
      "iter: 7300 , loss/100it: 0.394530089199543\n",
      "iter: 7400 , loss/100it: 0.3902935695648193\n",
      "iter: 7500 , loss/100it: 0.37691940635442733\n",
      "iter: 7600 , loss/100it: 0.37541848883032797\n",
      "iter: 7700 , loss/100it: 0.38528225511312486\n",
      "iter: 7800 , loss/100it: 0.377903151512146\n",
      "iter: 7900 , loss/100it: 0.3754355050623417\n",
      "iter: 8000 , loss/100it: 0.376976712346077\n",
      "iter: 8000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 85 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 81 %\n",
      "iter: 8100 , loss/100it: 0.3760049630701542\n",
      "iter: 8200 , loss/100it: 0.35840864062309263\n",
      "iter: 8300 , loss/100it: 0.3620308540761471\n",
      "iter: 8400 , loss/100it: 0.3548403134942055\n",
      "iter: 8500 , loss/100it: 0.35973685726523397\n",
      "iter: 8600 , loss/100it: 0.3390495043992996\n",
      "iter: 8700 , loss/100it: 0.3643656075000763\n",
      "iter: 8800 , loss/100it: 0.3615322935581207\n",
      "iter: 8900 , loss/100it: 0.3481856927275658\n",
      "iter: 9000 , loss/100it: 0.3544365094602108\n",
      "iter: 9000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 85 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 81 %\n",
      "iter: 9100 , loss/100it: 0.3558121804893017\n",
      "iter: 9200 , loss/100it: 0.32959993213415145\n",
      "iter: 9300 , loss/100it: 0.325576466023922\n",
      "iter: 9400 , loss/100it: 0.3465998354554176\n",
      "iter: 9500 , loss/100it: 0.3555997887253761\n",
      "iter: 9600 , loss/100it: 0.3385505755245686\n",
      "iter: 9700 , loss/100it: 0.3202826352417469\n",
      "iter: 9800 , loss/100it: 0.342661906927824\n",
      "iter: 9900 , loss/100it: 0.34241553738713265\n",
      "iter: 10000 , loss/100it: 0.3299937756359577\n",
      "iter: 10000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 86 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 82 %\n",
      "iter: 10100 , loss/100it: 0.3288593304157257\n",
      "iter: 10200 , loss/100it: 0.32738337114453314\n",
      "iter: 10300 , loss/100it: 0.3114121352136135\n",
      "iter: 10400 , loss/100it: 0.3156374189257622\n",
      "iter: 10500 , loss/100it: 0.3322283311188221\n",
      "iter: 10600 , loss/100it: 0.3340057446062565\n",
      "iter: 10700 , loss/100it: 0.30542764902114866\n",
      "iter: 10800 , loss/100it: 0.32119577541947364\n",
      "iter: 10900 , loss/100it: 0.33057416930794714\n",
      "iter: 11000 , loss/100it: 0.3042019733786583\n",
      "iter: 11000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 89 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 84 %\n",
      "iter: 11100 , loss/100it: 0.312324493676424\n",
      "iter: 11200 , loss/100it: 0.32911018580198287\n",
      "iter: 11300 , loss/100it: 0.3245732606947422\n",
      "iter: 11400 , loss/100it: 0.3044047626852989\n",
      "iter: 11500 , loss/100it: 0.3236350925266743\n",
      "iter: 11600 , loss/100it: 0.30361572504043577\n",
      "iter: 11700 , loss/100it: 0.28456704288721085\n",
      "iter: 11800 , loss/100it: 0.3087669475376606\n",
      "iter: 11900 , loss/100it: 0.3068047231435776\n",
      "iter: 12000 , loss/100it: 0.2999949687719345\n",
      "iter: 12000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 89 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 84 %\n",
      "iter: 12100 , loss/100it: 0.29490601271390915\n",
      "iter: 12200 , loss/100it: 0.303919023424387\n",
      "iter: 12300 , loss/100it: 0.3026049508154392\n",
      "iter: 12400 , loss/100it: 0.2781857047975063\n",
      "iter: 12500 , loss/100it: 0.2853378617018461\n",
      "iter: 12600 , loss/100it: 0.29626028284430506\n",
      "iter: 12700 , loss/100it: 0.3089257311820984\n",
      "iter: 12800 , loss/100it: 0.2784287463128567\n",
      "iter: 12900 , loss/100it: 0.29398368000984193\n",
      "iter: 13000 , loss/100it: 0.30782810658216475\n",
      "iter: 13000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 88 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 83 %\n",
      "iter: 13100 , loss/100it: 0.27321390450000765\n",
      "iter: 13200 , loss/100it: 0.2851514621078968\n",
      "iter: 13300 , loss/100it: 0.27954353839159013\n",
      "iter: 13400 , loss/100it: 0.2939648061990738\n",
      "iter: 13500 , loss/100it: 0.27820851400494573\n",
      "iter: 13600 , loss/100it: 0.27882847636938096\n",
      "iter: 13700 , loss/100it: 0.28885236114263535\n",
      "iter: 13800 , loss/100it: 0.2741644498705864\n",
      "iter: 13900 , loss/100it: 0.2677562341094017\n",
      "iter: 14000 , loss/100it: 0.278435682952404\n",
      "iter: 14000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 88 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 83 %\n",
      "iter: 14100 , loss/100it: 0.2952471132576466\n",
      "iter: 14200 , loss/100it: 0.26609111353755\n",
      "iter: 14300 , loss/100it: 0.28639447547495367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 14400 , loss/100it: 0.28717013269662856\n",
      "iter: 14500 , loss/100it: 0.25787654653191566\n",
      "iter: 14600 , loss/100it: 0.2702786347270012\n",
      "iter: 14700 , loss/100it: 0.2966419172286987\n",
      "iter: 14800 , loss/100it: 0.28369120985269547\n",
      "iter: 14900 , loss/100it: 0.2612015686929226\n",
      "iter: 15000 , loss/100it: 0.25448479637503624\n",
      "iter: 15000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 88 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 83 %\n",
      "iter: 15100 , loss/100it: 0.2920688197016716\n",
      "iter: 15200 , loss/100it: 0.2611998589336872\n",
      "iter: 15300 , loss/100it: 0.27193727403879164\n",
      "iter: 15400 , loss/100it: 0.265555290132761\n",
      "iter: 15500 , loss/100it: 0.2771045273542404\n",
      "iter: 15600 , loss/100it: 0.2647376573085785\n",
      "iter: 15700 , loss/100it: 0.26174304991960523\n",
      "iter: 15800 , loss/100it: 0.28459170684218404\n",
      "iter: 15900 , loss/100it: 0.2563937938213348\n",
      "iter: 16000 , loss/100it: 0.262112153545022\n",
      "iter: 16000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 91 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 86 %\n",
      "iter: 16100 , loss/100it: 0.26086012944579123\n",
      "iter: 16200 , loss/100it: 0.2710534231364727\n",
      "iter: 16300 , loss/100it: 0.2534495949745178\n",
      "iter: 16400 , loss/100it: 0.26242867931723596\n",
      "iter: 16500 , loss/100it: 0.2520840810239315\n",
      "iter: 16600 , loss/100it: 0.24196943663060666\n",
      "iter: 16700 , loss/100it: 0.24618700116872788\n",
      "iter: 16800 , loss/100it: 0.26674940034747124\n",
      "iter: 16900 , loss/100it: 0.2838177093863487\n",
      "iter: 17000 , loss/100it: 0.25193866312503815\n",
      "iter: 17000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 85 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 80 %\n",
      "iter: 17100 , loss/100it: 0.2519070802628994\n",
      "iter: 17200 , loss/100it: 0.25542658507823945\n",
      "iter: 17300 , loss/100it: 0.26737255461514\n",
      "iter: 17400 , loss/100it: 0.25359765768051146\n",
      "iter: 17500 , loss/100it: 0.26165021777153014\n",
      "iter: 17600 , loss/100it: 0.2569234944880009\n",
      "iter: 17700 , loss/100it: 0.23684969432651998\n",
      "iter: 17800 , loss/100it: 0.23669131562113763\n",
      "iter: 17900 , loss/100it: 0.2600096595287323\n",
      "iter: 18000 , loss/100it: 0.24934019796550275\n",
      "iter: 18000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 91 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 86 %\n",
      "iter: 18100 , loss/100it: 0.25247682981193065\n",
      "iter: 18200 , loss/100it: 0.260793833732605\n",
      "iter: 18300 , loss/100it: 0.2658077013492584\n",
      "iter: 18400 , loss/100it: 0.246058606505394\n",
      "iter: 18500 , loss/100it: 0.2567624309659004\n",
      "iter: 18600 , loss/100it: 0.2502044436335564\n",
      "iter: 18700 , loss/100it: 0.2329698857665062\n",
      "iter: 18800 , loss/100it: 0.2327362098544836\n",
      "iter: 18900 , loss/100it: 0.2302704980969429\n",
      "iter: 19000 , loss/100it: 0.27423491537570954\n",
      "iter: 19000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 91 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 85 %\n",
      "iter: 19100 , loss/100it: 0.23531864725053311\n",
      "iter: 19200 , loss/100it: 0.2486636918783188\n",
      "iter: 19300 , loss/100it: 0.25226044684648513\n",
      "iter: 19400 , loss/100it: 0.25221162393689156\n",
      "iter: 19500 , loss/100it: 0.2420900634676218\n",
      "iter: 19600 , loss/100it: 0.24470966160297394\n",
      "iter: 19700 , loss/100it: 0.24428877517580985\n",
      "iter: 19800 , loss/100it: 0.2263414505124092\n",
      "iter: 19900 , loss/100it: 0.23644779175519942\n",
      "iter: 20000 , loss/100it: 0.2699060563743114\n",
      "iter: 20000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 91 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 85 %\n",
      "iter: 20100 , loss/100it: 0.22071249939501286\n",
      "iter: 20200 , loss/100it: 0.24394079752266407\n",
      "iter: 20300 , loss/100it: 0.24920100942254067\n",
      "iter: 20400 , loss/100it: 0.23904328756034374\n",
      "iter: 20500 , loss/100it: 0.21797725617885588\n",
      "iter: 20600 , loss/100it: 0.2521955032646656\n",
      "iter: 20700 , loss/100it: 0.24047572374343873\n",
      "iter: 20800 , loss/100it: 0.23716120138764382\n",
      "iter: 20900 , loss/100it: 0.2242904756218195\n",
      "iter: 21000 , loss/100it: 0.2445153734087944\n",
      "iter: 21000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 92 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 86 %\n",
      "iter: 21100 , loss/100it: 0.24328980691730975\n",
      "iter: 21200 , loss/100it: 0.22474066518247127\n",
      "iter: 21300 , loss/100it: 0.2331724042445421\n",
      "iter: 21400 , loss/100it: 0.2458642404526472\n",
      "iter: 21500 , loss/100it: 0.252763279825449\n",
      "iter: 21600 , loss/100it: 0.23500180944800378\n",
      "iter: 21700 , loss/100it: 0.22159675247967242\n",
      "iter: 21800 , loss/100it: 0.24554322503507137\n",
      "iter: 21900 , loss/100it: 0.23292365737259388\n",
      "iter: 22000 , loss/100it: 0.22418937124311925\n",
      "iter: 22000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 89 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 83 %\n",
      "iter: 22100 , loss/100it: 0.24329893387854098\n",
      "iter: 22200 , loss/100it: 0.24386197850108146\n",
      "iter: 22300 , loss/100it: 0.21269763633608818\n",
      "iter: 22400 , loss/100it: 0.2187422139197588\n",
      "iter: 22500 , loss/100it: 0.2523752116411924\n",
      "iter: 22600 , loss/100it: 0.219488089941442\n",
      "iter: 22700 , loss/100it: 0.22294200446456672\n",
      "iter: 22800 , loss/100it: 0.23526899091899395\n",
      "iter: 22900 , loss/100it: 0.23971631735563279\n",
      "iter: 23000 , loss/100it: 0.22001951664686203\n",
      "iter: 23000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 90 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 85 %\n",
      "iter: 23100 , loss/100it: 0.22405164770781993\n",
      "iter: 23200 , loss/100it: 0.22337015524506568\n",
      "iter: 23300 , loss/100it: 0.22989477962255478\n",
      "iter: 23400 , loss/100it: 0.22352988213300706\n",
      "iter: 23500 , loss/100it: 0.23092244632542133\n",
      "iter: 23600 , loss/100it: 0.25339954540133475\n",
      "iter: 23700 , loss/100it: 0.2272836022078991\n",
      "iter: 23800 , loss/100it: 0.2145451617985964\n",
      "iter: 23900 , loss/100it: 0.23071861073374747\n",
      "iter: 24000 , loss/100it: 0.2202969404309988\n",
      "iter: 24000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 90 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 85 %\n",
      "iter: 24100 , loss/100it: 0.21568964853882788\n",
      "iter: 24200 , loss/100it: 0.22029714092612265\n",
      "iter: 24300 , loss/100it: 0.22956651613116263\n",
      "iter: 24400 , loss/100it: 0.21622955448925496\n",
      "iter: 24500 , loss/100it: 0.21385092414915563\n",
      "iter: 24600 , loss/100it: 0.23463887870311737\n",
      "iter: 24700 , loss/100it: 0.22560589514672758\n",
      "iter: 24800 , loss/100it: 0.22336006544530393\n",
      "iter: 24900 , loss/100it: 0.23677425131201743\n",
      "iter: 25000 , loss/100it: 0.22172342523932456\n",
      "iter: 25000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 89 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 84 %\n",
      "iter: 25100 , loss/100it: 0.2146053709834814\n",
      "iter: 25200 , loss/100it: 0.2139227733761072\n",
      "iter: 25300 , loss/100it: 0.23169489830732345\n",
      "iter: 25400 , loss/100it: 0.21864914193749427\n",
      "iter: 25500 , loss/100it: 0.20756710954010488\n",
      "iter: 25600 , loss/100it: 0.23225340142846107\n",
      "iter: 25700 , loss/100it: 0.23343628868460656\n",
      "iter: 25800 , loss/100it: 0.21162898540496827\n",
      "iter: 25900 , loss/100it: 0.21957040317356585\n",
      "iter: 26000 , loss/100it: 0.2205864577740431\n",
      "iter: 26000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 92 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 86 %\n",
      "iter: 26100 , loss/100it: 0.21240707509219647\n",
      "iter: 26200 , loss/100it: 0.19349299900233746\n",
      "iter: 26300 , loss/100it: 0.22369579277932644\n",
      "iter: 26400 , loss/100it: 0.22559815786778928\n",
      "iter: 26500 , loss/100it: 0.20700466588139535\n",
      "iter: 26600 , loss/100it: 0.21370174996554853\n",
      "iter: 26700 , loss/100it: 0.22582221873104572\n",
      "iter: 26800 , loss/100it: 0.2125065292418003\n",
      "iter: 26900 , loss/100it: 0.20144959911704063\n",
      "iter: 27000 , loss/100it: 0.2339145477861166\n",
      "iter: 27000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 91 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 85 %\n",
      "iter: 27100 , loss/100it: 0.22665352135896683\n",
      "iter: 27200 , loss/100it: 0.19838607043027878\n",
      "iter: 27300 , loss/100it: 0.2053508299589157\n",
      "iter: 27400 , loss/100it: 0.22373098120093346\n",
      "iter: 27500 , loss/100it: 0.22221811771392821\n",
      "iter: 27600 , loss/100it: 0.2138753792643547\n",
      "iter: 27700 , loss/100it: 0.20406121231615543\n",
      "iter: 27800 , loss/100it: 0.23174134872853755\n",
      "iter: 27900 , loss/100it: 0.20893275871872902\n",
      "iter: 28000 , loss/100it: 0.222009909003973\n",
      "iter: 28000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 91 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 85 %\n",
      "iter: 28100 , loss/100it: 0.22386725783348083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 28200 , loss/100it: 0.20655210837721824\n",
      "iter: 28300 , loss/100it: 0.22127913914620875\n",
      "iter: 28400 , loss/100it: 0.1959347252547741\n",
      "iter: 28500 , loss/100it: 0.22875115998089313\n",
      "iter: 28600 , loss/100it: 0.2066959834843874\n",
      "iter: 28700 , loss/100it: 0.19852043345570564\n",
      "iter: 28800 , loss/100it: 0.2137391234189272\n",
      "iter: 28900 , loss/100it: 0.20489991001784802\n",
      "iter: 29000 , loss/100it: 0.19660663701593875\n",
      "iter: 29000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 93 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 87 %\n",
      "iter: 29100 , loss/100it: 0.19943902157247068\n",
      "iter: 29200 , loss/100it: 0.22981174290180206\n",
      "iter: 29300 , loss/100it: 0.20408954314887523\n",
      "iter: 29400 , loss/100it: 0.2128651310503483\n",
      "iter: 29500 , loss/100it: 0.22354323744773866\n",
      "iter: 29600 , loss/100it: 0.20942187681794167\n",
      "iter: 29700 , loss/100it: 0.20648629210889338\n",
      "iter: 29800 , loss/100it: 0.22273162223398685\n",
      "iter: 29900 , loss/100it: 0.21552391290664674\n",
      "iter: 30000 , loss/100it: 0.19725684091448784\n",
      "iter: 30000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 92 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 86 %\n",
      "iter: 30100 , loss/100it: 0.20237065270543098\n",
      "iter: 30200 , loss/100it: 0.21023684933781625\n",
      "iter: 30300 , loss/100it: 0.20676388546824456\n",
      "iter: 30400 , loss/100it: 0.19238584138453008\n",
      "iter: 30500 , loss/100it: 0.21261440560221673\n",
      "iter: 30600 , loss/100it: 0.22554785080254078\n",
      "iter: 30700 , loss/100it: 0.18032026678323745\n",
      "iter: 30800 , loss/100it: 0.20398490712046624\n",
      "iter: 30900 , loss/100it: 0.21380676321685313\n",
      "iter: 31000 , loss/100it: 0.20936357751488685\n",
      "iter: 31000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 93 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 88 %\n",
      "iter: 31100 , loss/100it: 0.19579733461141585\n",
      "iter: 31200 , loss/100it: 0.19971845492720605\n",
      "iter: 31300 , loss/100it: 0.21299999967217445\n",
      "iter: 31400 , loss/100it: 0.2026537049561739\n",
      "iter: 31500 , loss/100it: 0.1969952066987753\n",
      "iter: 31600 , loss/100it: 0.2179760544747114\n",
      "iter: 31700 , loss/100it: 0.2123876192420721\n",
      "iter: 31800 , loss/100it: 0.19920212924480438\n",
      "iter: 31900 , loss/100it: 0.1952259749919176\n",
      "iter: 32000 , loss/100it: 0.20544968865811825\n",
      "iter: 32000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 91 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 85 %\n",
      "iter: 32100 , loss/100it: 0.15107114415615797\n",
      "iter: 32200 , loss/100it: 0.11944964926689863\n",
      "iter: 32300 , loss/100it: 0.11101003557443619\n",
      "iter: 32400 , loss/100it: 0.09930205900222062\n",
      "iter: 32500 , loss/100it: 0.08780584044754505\n",
      "iter: 32600 , loss/100it: 0.08963901739567519\n",
      "iter: 32700 , loss/100it: 0.0809120630286634\n",
      "iter: 32800 , loss/100it: 0.08454148290678859\n",
      "iter: 32900 , loss/100it: 0.07816301755607129\n",
      "iter: 33000 , loss/100it: 0.08027325386181473\n",
      "iter: 33000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 98 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 91 %\n",
      "iter: 33100 , loss/100it: 0.0782336244545877\n",
      "iter: 33200 , loss/100it: 0.07059598475694656\n",
      "iter: 33300 , loss/100it: 0.07346595024690032\n",
      "iter: 33400 , loss/100it: 0.06807571657001972\n",
      "iter: 33500 , loss/100it: 0.06973690148442983\n",
      "iter: 33600 , loss/100it: 0.06460352655500173\n",
      "iter: 33700 , loss/100it: 0.06618765044957399\n",
      "iter: 33800 , loss/100it: 0.06651232892647385\n",
      "iter: 33900 , loss/100it: 0.060424277260899543\n",
      "iter: 34000 , loss/100it: 0.06308897413313388\n",
      "iter: 34000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 98 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 91 %\n",
      "iter: 34100 , loss/100it: 0.060632998142391446\n",
      "iter: 34200 , loss/100it: 0.05913206747267395\n",
      "iter: 34300 , loss/100it: 0.055334810968488454\n",
      "iter: 34400 , loss/100it: 0.05628965137526393\n",
      "iter: 34500 , loss/100it: 0.058417026326060294\n",
      "iter: 34600 , loss/100it: 0.053412252264097335\n",
      "iter: 34700 , loss/100it: 0.05620295183733106\n",
      "iter: 34800 , loss/100it: 0.05730650881305337\n",
      "iter: 34900 , loss/100it: 0.05641816985793412\n",
      "iter: 35000 , loss/100it: 0.050104613238945606\n",
      "iter: 35000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 99 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 91 %\n",
      "iter: 35100 , loss/100it: 0.05062984451651573\n",
      "iter: 35200 , loss/100it: 0.053910841001197696\n",
      "iter: 35300 , loss/100it: 0.05341792198829353\n",
      "iter: 35400 , loss/100it: 0.049917465541511774\n",
      "iter: 35500 , loss/100it: 0.049444888420403\n",
      "iter: 35600 , loss/100it: 0.04587538968771696\n",
      "iter: 35700 , loss/100it: 0.0490078676212579\n",
      "iter: 35800 , loss/100it: 0.046902273120358585\n",
      "iter: 35900 , loss/100it: 0.04912601288408041\n",
      "iter: 36000 , loss/100it: 0.043437200989574196\n",
      "iter: 36000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 99 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 91 %\n",
      "iter: 36100 , loss/100it: 0.040655382834374906\n",
      "iter: 36200 , loss/100it: 0.049453814709559084\n",
      "iter: 36300 , loss/100it: 0.04338035532273352\n",
      "iter: 36400 , loss/100it: 0.0423343232087791\n",
      "iter: 36500 , loss/100it: 0.04295066012069583\n",
      "iter: 36600 , loss/100it: 0.03884458914399147\n",
      "iter: 36700 , loss/100it: 0.03994054879061878\n",
      "iter: 36800 , loss/100it: 0.042494679419323805\n",
      "iter: 36900 , loss/100it: 0.03838940605986863\n",
      "iter: 37000 , loss/100it: 0.03832739207427949\n",
      "iter: 37000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 99 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 91 %\n",
      "iter: 37100 , loss/100it: 0.0352988217305392\n",
      "iter: 37200 , loss/100it: 0.04111552495509386\n",
      "iter: 37300 , loss/100it: 0.04371198049746454\n",
      "iter: 37400 , loss/100it: 0.03729254155419767\n",
      "iter: 37500 , loss/100it: 0.034943197974935176\n",
      "iter: 37600 , loss/100it: 0.040582770071923735\n",
      "iter: 37700 , loss/100it: 0.03857543702237308\n",
      "iter: 37800 , loss/100it: 0.03778701139613986\n",
      "iter: 37900 , loss/100it: 0.04025700781494379\n",
      "iter: 38000 , loss/100it: 0.03834345171693712\n",
      "iter: 38000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 99 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 91 %\n",
      "iter: 38100 , loss/100it: 0.03720716904848814\n",
      "iter: 38200 , loss/100it: 0.030873536034487187\n",
      "iter: 38300 , loss/100it: 0.035028751804493365\n",
      "iter: 38400 , loss/100it: 0.038190234368667\n",
      "iter: 38500 , loss/100it: 0.03178693502675742\n",
      "iter: 38600 , loss/100it: 0.03306131925433874\n",
      "iter: 38700 , loss/100it: 0.034316734168678524\n",
      "iter: 38800 , loss/100it: 0.03343298099935055\n",
      "iter: 38900 , loss/100it: 0.029733106875792146\n",
      "iter: 39000 , loss/100it: 0.032845533601939675\n",
      "iter: 39000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 99 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 91 %\n",
      "iter: 39100 , loss/100it: 0.03452405392657965\n",
      "iter: 39200 , loss/100it: 0.029734662179835142\n",
      "iter: 39300 , loss/100it: 0.03326667868997902\n",
      "iter: 39400 , loss/100it: 0.033844150681979955\n",
      "iter: 39500 , loss/100it: 0.032550251772627235\n",
      "iter: 39600 , loss/100it: 0.030587977920658885\n",
      "iter: 39700 , loss/100it: 0.030334552093409003\n",
      "iter: 39800 , loss/100it: 0.030316672828048466\n",
      "iter: 39900 , loss/100it: 0.02827300311997533\n",
      "iter: 40000 , loss/100it: 0.030924282264895738\n",
      "iter: 40000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 99 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 91 %\n",
      "iter: 40100 , loss/100it: 0.031590527291409674\n",
      "iter: 40200 , loss/100it: 0.025911582484841347\n",
      "iter: 40300 , loss/100it: 0.028970274748280643\n",
      "iter: 40400 , loss/100it: 0.028323282888159156\n",
      "iter: 40500 , loss/100it: 0.028126238328404725\n",
      "iter: 40600 , loss/100it: 0.026338384854607284\n",
      "iter: 40700 , loss/100it: 0.025461997664533557\n",
      "iter: 40800 , loss/100it: 0.02699664463754743\n",
      "iter: 40900 , loss/100it: 0.026027308427728713\n",
      "iter: 41000 , loss/100it: 0.030623964993283154\n",
      "iter: 41000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 99 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 91 %\n",
      "iter: 41100 , loss/100it: 0.025999926798976957\n",
      "iter: 41200 , loss/100it: 0.02746451646089554\n",
      "iter: 41300 , loss/100it: 0.025186703458894046\n",
      "iter: 41400 , loss/100it: 0.028341574233490974\n",
      "iter: 41500 , loss/100it: 0.02459796362556517\n",
      "iter: 41600 , loss/100it: 0.02415483694523573\n",
      "iter: 41700 , loss/100it: 0.026696204931940883\n",
      "iter: 41800 , loss/100it: 0.024650690197013318\n",
      "iter: 41900 , loss/100it: 0.02958754189778119\n",
      "iter: 42000 , loss/100it: 0.023308368264697493\n",
      "iter: 42000 , test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 99 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 91 %\n",
      "iter: 42100 , loss/100it: 0.023613581624813376\n",
      "iter: 42200 , loss/100it: 0.02630859647411853\n",
      "iter: 42300 , loss/100it: 0.02180626029614359\n",
      "iter: 42400 , loss/100it: 0.02403525535017252\n",
      "iter: 42500 , loss/100it: 0.0246002602763474\n",
      "iter: 42600 , loss/100it: 0.025439336160197855\n",
      "iter: 42700 , loss/100it: 0.022640308463014663\n",
      "iter: 42800 , loss/100it: 0.0263079794915393\n",
      "iter: 42900 , loss/100it: 0.02456608631182462\n",
      "iter: 43000 , loss/100it: 0.022244249135255814\n",
      "iter: 43000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 99 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 91 %\n",
      "iter: 43100 , loss/100it: 0.02260684992186725\n",
      "iter: 43200 , loss/100it: 0.02408226082334295\n",
      "iter: 43300 , loss/100it: 0.023454634512308985\n",
      "iter: 43400 , loss/100it: 0.021855805637314915\n",
      "iter: 43500 , loss/100it: 0.021119136072229594\n",
      "iter: 43600 , loss/100it: 0.022863558735698463\n",
      "iter: 43700 , loss/100it: 0.023120336297433822\n",
      "iter: 43800 , loss/100it: 0.02101169591071084\n",
      "iter: 43900 , loss/100it: 0.01971941031049937\n",
      "iter: 44000 , loss/100it: 0.020340407516341655\n",
      "iter: 44000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 99 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 91 %\n",
      "iter: 44100 , loss/100it: 0.018006461572367696\n",
      "iter: 44200 , loss/100it: 0.01948036201298237\n",
      "iter: 44300 , loss/100it: 0.01955041796900332\n",
      "iter: 44400 , loss/100it: 0.020723382525611667\n",
      "iter: 44500 , loss/100it: 0.020584785745013504\n",
      "iter: 44600 , loss/100it: 0.02379411442670971\n",
      "iter: 44700 , loss/100it: 0.021711530117318033\n",
      "iter: 44800 , loss/100it: 0.019704064514953643\n",
      "iter: 44900 , loss/100it: 0.02384217724669725\n",
      "iter: 45000 , loss/100it: 0.020878089000470935\n",
      "iter: 45000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 99 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 91 %\n",
      "iter: 45100 , loss/100it: 0.019327780154999346\n",
      "iter: 45200 , loss/100it: 0.02071438228012994\n",
      "iter: 45300 , loss/100it: 0.020383348180912433\n",
      "iter: 45400 , loss/100it: 0.021270655170083044\n",
      "iter: 45500 , loss/100it: 0.02124527782900259\n",
      "iter: 45600 , loss/100it: 0.01825747315539047\n",
      "iter: 45700 , loss/100it: 0.022367256958968938\n",
      "iter: 45800 , loss/100it: 0.020975882930215448\n",
      "iter: 45900 , loss/100it: 0.01895566192572005\n",
      "iter: 46000 , loss/100it: 0.018065997012890876\n",
      "iter: 46000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 99 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 91 %\n",
      "iter: 46100 , loss/100it: 0.02017845645081252\n",
      "iter: 46200 , loss/100it: 0.021829214636236428\n",
      "iter: 46300 , loss/100it: 0.01896787089994177\n",
      "iter: 46400 , loss/100it: 0.020086543674115092\n",
      "iter: 46500 , loss/100it: 0.018120144715067\n",
      "iter: 46600 , loss/100it: 0.01587874472490512\n",
      "iter: 46700 , loss/100it: 0.01983151350170374\n",
      "iter: 46800 , loss/100it: 0.020077738447580488\n",
      "iter: 46900 , loss/100it: 0.016957881569396704\n",
      "iter: 47000 , loss/100it: 0.019017922135535627\n",
      "iter: 47000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 99 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 91 %\n",
      "iter: 47100 , loss/100it: 0.018030135890003293\n",
      "iter: 47200 , loss/100it: 0.017647226217668503\n",
      "iter: 47300 , loss/100it: 0.01864697830285877\n",
      "iter: 47400 , loss/100it: 0.01964215188054368\n",
      "iter: 47500 , loss/100it: 0.019450820037163793\n",
      "iter: 47600 , loss/100it: 0.015947816560510544\n",
      "iter: 47700 , loss/100it: 0.01618308760691434\n",
      "iter: 47800 , loss/100it: 0.016951405245345087\n",
      "iter: 47900 , loss/100it: 0.017655221471795813\n",
      "iter: 48000 , loss/100it: 0.018557914746925235\n",
      "iter: 48000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 99 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 91 %\n",
      "iter: 48100 , loss/100it: 0.017926535953301938\n",
      "iter: 48200 , loss/100it: 0.016213724836707116\n",
      "iter: 48300 , loss/100it: 0.015556396655738354\n",
      "iter: 48400 , loss/100it: 0.014805042175576091\n",
      "iter: 48500 , loss/100it: 0.013106900098500773\n",
      "iter: 48600 , loss/100it: 0.01756290555000305\n",
      "iter: 48700 , loss/100it: 0.014184911118354649\n",
      "iter: 48800 , loss/100it: 0.014214787927921862\n",
      "iter: 48900 , loss/100it: 0.015675760767189784\n",
      "iter: 49000 , loss/100it: 0.01069367524352856\n",
      "iter: 49000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 99 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 91 %\n",
      "iter: 49100 , loss/100it: 0.013416318089002743\n",
      "iter: 49200 , loss/100it: 0.014589086214546115\n",
      "iter: 49300 , loss/100it: 0.014562612557783723\n",
      "iter: 49400 , loss/100it: 0.013766563615063206\n",
      "iter: 49500 , loss/100it: 0.01322441601776518\n",
      "iter: 49600 , loss/100it: 0.013640836300328373\n",
      "iter: 49700 , loss/100it: 0.01315857851994224\n",
      "iter: 49800 , loss/100it: 0.012707362223882229\n",
      "iter: 49900 , loss/100it: 0.012957342830486596\n",
      "iter: 50000 , loss/100it: 0.013733695669798181\n",
      "iter: 50000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 99 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 91 %\n",
      "iter: 50100 , loss/100it: 0.012832462999504059\n",
      "iter: 50200 , loss/100it: 0.012527329084696249\n",
      "iter: 50300 , loss/100it: 0.01296286921016872\n",
      "iter: 50400 , loss/100it: 0.011760996556840837\n",
      "iter: 50500 , loss/100it: 0.013883946831338107\n",
      "iter: 50600 , loss/100it: 0.012745648070704193\n",
      "iter: 50700 , loss/100it: 0.01330434978241101\n",
      "iter: 50800 , loss/100it: 0.012366506829857826\n",
      "iter: 50900 , loss/100it: 0.012167603459674865\n",
      "iter: 51000 , loss/100it: 0.012548919152468443\n",
      "iter: 51000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 99 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 91 %\n",
      "iter: 51100 , loss/100it: 0.01200490843039006\n",
      "iter: 51200 , loss/100it: 0.011190562937408687\n",
      "iter: 51300 , loss/100it: 0.014289778280071915\n",
      "iter: 51400 , loss/100it: 0.010868504646932706\n",
      "iter: 51500 , loss/100it: 0.010826123998267576\n",
      "iter: 51600 , loss/100it: 0.012989397024502978\n",
      "iter: 51700 , loss/100it: 0.012830509068444372\n",
      "iter: 51800 , loss/100it: 0.012631600166205317\n",
      "iter: 51900 , loss/100it: 0.01146024358458817\n",
      "iter: 52000 , loss/100it: 0.014089082721620799\n",
      "iter: 52000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 99 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 91 %\n",
      "iter: 52100 , loss/100it: 0.012234286880120635\n",
      "iter: 52200 , loss/100it: 0.01140201716683805\n",
      "iter: 52300 , loss/100it: 0.012040569122182205\n",
      "iter: 52400 , loss/100it: 0.011404794891132043\n",
      "iter: 52500 , loss/100it: 0.013164339298382401\n",
      "iter: 52600 , loss/100it: 0.012694868472171947\n",
      "iter: 52700 , loss/100it: 0.013733429199201055\n",
      "iter: 52800 , loss/100it: 0.012080450394423679\n",
      "iter: 52900 , loss/100it: 0.012391824449878186\n",
      "iter: 53000 , loss/100it: 0.012993926764465868\n",
      "iter: 53000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 99 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 91 %\n",
      "iter: 53100 , loss/100it: 0.01242438999703154\n",
      "iter: 53200 , loss/100it: 0.011174756467808038\n",
      "iter: 53300 , loss/100it: 0.013045598894823342\n",
      "iter: 53400 , loss/100it: 0.013911300346953794\n",
      "iter: 53500 , loss/100it: 0.010830446819309145\n",
      "iter: 53600 , loss/100it: 0.012314877383760177\n",
      "iter: 53700 , loss/100it: 0.012662762781837955\n",
      "iter: 53800 , loss/100it: 0.011658436984289438\n",
      "iter: 53900 , loss/100it: 0.013169880089117214\n",
      "iter: 54000 , loss/100it: 0.01169573787949048\n",
      "iter: 54000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 99 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 91 %\n",
      "iter: 54100 , loss/100it: 0.012613702919334174\n",
      "iter: 54200 , loss/100it: 0.012998611201765016\n",
      "iter: 54300 , loss/100it: 0.012495722793973983\n",
      "iter: 54400 , loss/100it: 0.011716240402311087\n",
      "iter: 54500 , loss/100it: 0.01253887366852723\n",
      "iter: 54600 , loss/100it: 0.010795327508822084\n",
      "iter: 54700 , loss/100it: 0.011188261001370848\n",
      "iter: 54800 , loss/100it: 0.011933656982146204\n",
      "iter: 54900 , loss/100it: 0.011845799810253084\n",
      "iter: 55000 , loss/100it: 0.012054222438018769\n",
      "iter: 55000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 99 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 91 %\n",
      "iter: 55100 , loss/100it: 0.012777883724775166\n",
      "iter: 55200 , loss/100it: 0.011783161691855639\n",
      "iter: 55300 , loss/100it: 0.012080033294623718\n",
      "iter: 55400 , loss/100it: 0.010412756780860946\n",
      "iter: 55500 , loss/100it: 0.010814743775408715\n",
      "iter: 55600 , loss/100it: 0.012834863865282386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 55700 , loss/100it: 0.011572132465662435\n",
      "iter: 55800 , loss/100it: 0.01112701523466967\n",
      "iter: 55900 , loss/100it: 0.01162298531504348\n",
      "iter: 56000 , loss/100it: 0.01177012242260389\n",
      "iter: 56000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 99 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 91 %\n",
      "iter: 56100 , loss/100it: 0.01040609851363115\n",
      "iter: 56200 , loss/100it: 0.01190515401540324\n",
      "iter: 56300 , loss/100it: 0.01171842470066622\n",
      "iter: 56400 , loss/100it: 0.011743682480882853\n",
      "iter: 56500 , loss/100it: 0.010592646312434227\n",
      "iter: 56600 , loss/100it: 0.010156195313902572\n",
      "iter: 56700 , loss/100it: 0.012468336666934192\n",
      "iter: 56800 , loss/100it: 0.010860942915314808\n",
      "iter: 56900 , loss/100it: 0.012471669958904386\n",
      "iter: 57000 , loss/100it: 0.012355541879078374\n",
      "iter: 57000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 99 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 91 %\n",
      "iter: 57100 , loss/100it: 0.010857278830371797\n",
      "iter: 57200 , loss/100it: 0.011716040972387418\n",
      "iter: 57300 , loss/100it: 0.0104599221306853\n",
      "iter: 57400 , loss/100it: 0.010957119192462415\n",
      "iter: 57500 , loss/100it: 0.011168883515056223\n",
      "iter: 57600 , loss/100it: 0.011207712442846969\n",
      "iter: 57700 , loss/100it: 0.01031759363017045\n",
      "iter: 57800 , loss/100it: 0.010390509743010624\n",
      "iter: 57900 , loss/100it: 0.01200930479564704\n",
      "iter: 58000 , loss/100it: 0.010320734812412411\n",
      "iter: 58000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 99 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 91 %\n",
      "iter: 58100 , loss/100it: 0.010288780820555985\n",
      "iter: 58200 , loss/100it: 0.010822397108422593\n",
      "iter: 58300 , loss/100it: 0.011198072502156719\n",
      "iter: 58400 , loss/100it: 0.011207614592276514\n",
      "iter: 58500 , loss/100it: 0.010425003968412056\n",
      "iter: 58600 , loss/100it: 0.009597238212591038\n",
      "iter: 58700 , loss/100it: 0.010754219604423269\n",
      "iter: 58800 , loss/100it: 0.01108234609127976\n",
      "iter: 58900 , loss/100it: 0.01068494537845254\n",
      "iter: 59000 , loss/100it: 0.009545791853452102\n",
      "iter: 59000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 99 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 91 %\n",
      "iter: 59100 , loss/100it: 0.011110506590921432\n",
      "iter: 59200 , loss/100it: 0.010501253527472727\n",
      "iter: 59300 , loss/100it: 0.010797598211793229\n",
      "iter: 59400 , loss/100it: 0.010552758775302208\n",
      "iter: 59500 , loss/100it: 0.009730501763988287\n",
      "iter: 59600 , loss/100it: 0.011470739885699004\n",
      "iter: 59700 , loss/100it: 0.011406221449142322\n",
      "iter: 59800 , loss/100it: 0.011079548405250534\n",
      "iter: 59900 , loss/100it: 0.011561246203491464\n",
      "iter: 60000 , loss/100it: 0.010843834578408859\n",
      "iter: 60000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 99 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 91 %\n",
      "iter: 60100 , loss/100it: 0.011269168582512066\n",
      "iter: 60200 , loss/100it: 0.009868791848421097\n",
      "iter: 60300 , loss/100it: 0.010092682932736352\n",
      "iter: 60400 , loss/100it: 0.01068973351502791\n",
      "iter: 60500 , loss/100it: 0.011262868442572653\n",
      "iter: 60600 , loss/100it: 0.011921351861674338\n",
      "iter: 60700 , loss/100it: 0.011304536745883524\n",
      "iter: 60800 , loss/100it: 0.011647999045671896\n",
      "iter: 60900 , loss/100it: 0.010714347357861698\n",
      "iter: 61000 , loss/100it: 0.010920576326316222\n",
      "iter: 61000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 99 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 91 %\n",
      "iter: 61100 , loss/100it: 0.01137665166053921\n",
      "iter: 61200 , loss/100it: 0.010500278871040792\n",
      "iter: 61300 , loss/100it: 0.008357623066985979\n",
      "iter: 61400 , loss/100it: 0.011705553432693704\n",
      "iter: 61500 , loss/100it: 0.011133198575116694\n",
      "iter: 61600 , loss/100it: 0.01117243118933402\n",
      "iter: 61700 , loss/100it: 0.010869746503885835\n",
      "iter: 61800 , loss/100it: 0.009857628700556233\n",
      "iter: 61900 , loss/100it: 0.010740351357962936\n",
      "iter: 62000 , loss/100it: 0.010235344669781625\n",
      "iter: 62000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 99 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 91 %\n",
      "iter: 62100 , loss/100it: 0.010356576880440116\n",
      "iter: 62200 , loss/100it: 0.010858873948454856\n",
      "iter: 62300 , loss/100it: 0.010030472833896055\n",
      "iter: 62400 , loss/100it: 0.01026913218665868\n",
      "iter: 62500 , loss/100it: 0.010575613364344462\n",
      "iter: 62600 , loss/100it: 0.010328415135154501\n",
      "iter: 62700 , loss/100it: 0.011952979081543162\n",
      "iter: 62800 , loss/100it: 0.010828787230420857\n",
      "iter: 62900 , loss/100it: 0.009593515319284051\n",
      "iter: 63000 , loss/100it: 0.01027295231120661\n",
      "iter: 63000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 99 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 91 %\n",
      "iter: 63100 , loss/100it: 0.010578876485233195\n",
      "iter: 63200 , loss/100it: 0.011627511031692848\n",
      "iter: 63300 , loss/100it: 0.012137028235010804\n",
      "iter: 63400 , loss/100it: 0.010233278160449118\n",
      "iter: 63500 , loss/100it: 0.009802487654378638\n",
      "iter: 63600 , loss/100it: 0.010087799668544903\n",
      "iter: 63700 , loss/100it: 0.012112980969250202\n",
      "iter: 63800 , loss/100it: 0.00925060264649801\n",
      "iter: 63900 , loss/100it: 0.009773703173268587\n",
      "iter: 64000 , loss/100it: 0.011788332292344422\n",
      "iter: 64000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 99 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 91 %\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter()\n",
    "running_loss = 0.0\n",
    "net.train();\n",
    "while(it<=end_iter):\n",
    "    for data in trainloader:\n",
    "        it+=1\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        \n",
    "        #random flip, constant padding, random crop\n",
    "        if np.random.randint(0,2) == 0:\n",
    "            inputs = torch.flip(inputs, [3])\n",
    "        inputs = F.pad(inputs, (4, 4, 4, 4))\n",
    "        W = inputs.size()[2]\n",
    "        H = inputs.size()[3] \n",
    "        Ws = np.random.randint(0, W-32, 1)[0]\n",
    "        Hs = np.random.randint(0, H-32, 1)[0]\n",
    "        inputs = inputs[:,:,Ws:Ws+32,Hs:Hs+32]\n",
    "        \n",
    "        #training\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if it == 32000 or it == 48000:\n",
    "            scheduler.step()\n",
    "            PATH = './cifar_10_resnet'+str(N*6+2)+'_iter'+str(it)+'.pth'\n",
    "            torch.save(net.state_dict(), PATH)\n",
    "            \n",
    "        running_loss += loss.item()\n",
    "        if it % 100 == 0:\n",
    "            print(\"iter:\",it,\", loss/100it:\",running_loss / 100)\n",
    "            writer.add_scalar('training loss', running_loss / 100,it)\n",
    "            running_loss = 0.0\n",
    "            \n",
    "        if it % 1000 == 0:\n",
    "            print(\"iter:\",it,\", test\")\n",
    "            net.eval();\n",
    "            #for Training set\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            with torch.no_grad():\n",
    "                for i,data in enumerate(trainloader):\n",
    "                    if i % 100 == 0:\n",
    "                        print(i,\"/\",len(trainloader))\n",
    "                    inputs, labels = data[0].to(device), data[1].to(device)\n",
    "                    \n",
    "                    outputs = net(inputs)\n",
    "\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "            print('Accuracy on training images: %d %%' % (100 * correct / total))\n",
    "            writer.add_scalar('Acc on training', (100 * correct / total),it)\n",
    "            \n",
    "            #for Test set\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            with torch.no_grad():\n",
    "                for i,data in enumerate(testloader):\n",
    "                    if i % 50 == 0:\n",
    "                        print(i,\"/\",len(testloader))\n",
    "                    inputs, labels = data[0].to(device), data[1].to(device)\n",
    "                    \n",
    "                    outputs = net(inputs)\n",
    "\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "            print('Accuracy on test images: %d %%' % (100 * correct / total))\n",
    "            writer.add_scalar('Acc on testing', (100 * correct / total),it)\n",
    "            net.train();\n",
    "        \n",
    "print('Finished Training')\n",
    "\n",
    "PATH = './cifar_10_resnet'+str(N*6+2)+'_iter'+str(it)+'.pth'\n",
    "torch.save(net.state_dict(), PATH)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet 20\n",
    "N = 3\n",
    "\n",
    "net = Net(N);\n",
    "net.apply(init_weights);\n",
    "net.to(device);\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1, weight_decay = 0.0001, momentum=0.9)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.1)\n",
    "\n",
    "\n",
    "start_iter = 0\n",
    "end_iter = 64000\n",
    "it = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 100 , loss/100it: 2.229663013219833\n",
      "iter: 200 , loss/100it: 1.7424214959144593\n",
      "iter: 300 , loss/100it: 1.611091344356537\n",
      "iter: 400 , loss/100it: 1.4741445863246918\n",
      "iter: 500 , loss/100it: 1.373933925628662\n",
      "iter: 600 , loss/100it: 1.2640364730358125\n",
      "iter: 700 , loss/100it: 1.198943825364113\n",
      "iter: 800 , loss/100it: 1.123560608625412\n",
      "iter: 900 , loss/100it: 1.0392798268795014\n",
      "iter: 1000 , loss/100it: 1.0076363807916642\n",
      "iter: 1000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 59 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 59 %\n",
      "iter: 1100 , loss/100it: 0.9286403733491898\n",
      "iter: 1200 , loss/100it: 0.9004082947969436\n",
      "iter: 1300 , loss/100it: 0.8412130254507065\n",
      "iter: 1400 , loss/100it: 0.813558389544487\n",
      "iter: 1500 , loss/100it: 0.7527267789840698\n",
      "iter: 1600 , loss/100it: 0.7688713455200196\n",
      "iter: 1700 , loss/100it: 0.7281544363498688\n",
      "iter: 1800 , loss/100it: 0.7010033693909645\n",
      "iter: 1900 , loss/100it: 0.6805355855822564\n",
      "iter: 2000 , loss/100it: 0.6827689230442047\n",
      "iter: 2000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 77 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 76 %\n",
      "iter: 2100 , loss/100it: 0.653838184773922\n",
      "iter: 2200 , loss/100it: 0.646562237739563\n",
      "iter: 2300 , loss/100it: 0.6086978542804719\n",
      "iter: 2400 , loss/100it: 0.6039990159869194\n",
      "iter: 2500 , loss/100it: 0.5917641884088516\n",
      "iter: 2600 , loss/100it: 0.5687835803627967\n",
      "iter: 2700 , loss/100it: 0.5693521735072136\n",
      "iter: 2800 , loss/100it: 0.5669301018118859\n",
      "iter: 2900 , loss/100it: 0.5399817427992821\n",
      "iter: 3000 , loss/100it: 0.5386573234200478\n",
      "iter: 3000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 80 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 78 %\n",
      "iter: 3100 , loss/100it: 0.548641896545887\n",
      "iter: 3200 , loss/100it: 0.5165962812304496\n",
      "iter: 3300 , loss/100it: 0.5075938904285431\n",
      "iter: 3400 , loss/100it: 0.5139520740509034\n",
      "iter: 3500 , loss/100it: 0.5239261350035668\n",
      "iter: 3600 , loss/100it: 0.49561815410852433\n",
      "iter: 3700 , loss/100it: 0.4827631360292435\n",
      "iter: 3800 , loss/100it: 0.49318847328424453\n",
      "iter: 3900 , loss/100it: 0.4754764062166214\n",
      "iter: 4000 , loss/100it: 0.469592105448246\n",
      "iter: 4000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 83 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 80 %\n",
      "iter: 4100 , loss/100it: 0.4664513957500458\n",
      "iter: 4200 , loss/100it: 0.4599382194876671\n",
      "iter: 4300 , loss/100it: 0.4538142603635788\n",
      "iter: 4400 , loss/100it: 0.4401337906718254\n",
      "iter: 4500 , loss/100it: 0.4499763143062592\n",
      "iter: 4600 , loss/100it: 0.4728211250901222\n",
      "iter: 4700 , loss/100it: 0.42275969609618186\n",
      "iter: 4800 , loss/100it: 0.43450860753655435\n",
      "iter: 4900 , loss/100it: 0.4421983325481415\n",
      "iter: 5000 , loss/100it: 0.4182977080345154\n",
      "iter: 5000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 84 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 81 %\n",
      "iter: 5100 , loss/100it: 0.4373527240753174\n",
      "iter: 5200 , loss/100it: 0.4080094739794731\n",
      "iter: 5300 , loss/100it: 0.41125747859477996\n",
      "iter: 5400 , loss/100it: 0.40792348131537437\n",
      "iter: 5500 , loss/100it: 0.4120760650932789\n",
      "iter: 5600 , loss/100it: 0.41070794850587844\n",
      "iter: 5700 , loss/100it: 0.3848679128289223\n",
      "iter: 5800 , loss/100it: 0.3938547295331955\n",
      "iter: 5900 , loss/100it: 0.3976664100587368\n",
      "iter: 6000 , loss/100it: 0.411663134843111\n",
      "iter: 6000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 87 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 84 %\n",
      "iter: 6100 , loss/100it: 0.3837899093329906\n",
      "iter: 6200 , loss/100it: 0.38310222864151\n",
      "iter: 6300 , loss/100it: 0.3779591323435307\n",
      "iter: 6400 , loss/100it: 0.3781141608953476\n",
      "iter: 6500 , loss/100it: 0.3759661516547203\n",
      "iter: 6600 , loss/100it: 0.3811780855059624\n",
      "iter: 6700 , loss/100it: 0.38254125401377675\n",
      "iter: 6800 , loss/100it: 0.3527404533326626\n",
      "iter: 6900 , loss/100it: 0.3667668601870537\n",
      "iter: 7000 , loss/100it: 0.3825039859116077\n",
      "iter: 7000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 87 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 83 %\n",
      "iter: 7100 , loss/100it: 0.35583504229784013\n",
      "iter: 7200 , loss/100it: 0.3613864225149155\n",
      "iter: 7300 , loss/100it: 0.35819830164313315\n",
      "iter: 7400 , loss/100it: 0.36723949447274207\n",
      "iter: 7500 , loss/100it: 0.3385763347148895\n",
      "iter: 7600 , loss/100it: 0.34951346173882486\n",
      "iter: 7700 , loss/100it: 0.3692037759721279\n",
      "iter: 7800 , loss/100it: 0.3274696472287178\n",
      "iter: 7900 , loss/100it: 0.346476898342371\n",
      "iter: 8000 , loss/100it: 0.3527474746108055\n",
      "iter: 8000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 88 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 84 %\n",
      "iter: 8100 , loss/100it: 0.35713974431157114\n",
      "iter: 8200 , loss/100it: 0.33545643255114554\n",
      "iter: 8300 , loss/100it: 0.32942069858312606\n",
      "iter: 8400 , loss/100it: 0.34268917635083196\n",
      "iter: 8500 , loss/100it: 0.32331225022673604\n",
      "iter: 8600 , loss/100it: 0.32914786517620087\n",
      "iter: 8700 , loss/100it: 0.33215818747878073\n",
      "iter: 8800 , loss/100it: 0.34584878996014595\n",
      "iter: 8900 , loss/100it: 0.3173256713151932\n",
      "iter: 9000 , loss/100it: 0.32569206923246385\n",
      "iter: 9000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 83 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 80 %\n",
      "iter: 9100 , loss/100it: 0.3332020001113415\n",
      "iter: 9200 , loss/100it: 0.31186583325266837\n",
      "iter: 9300 , loss/100it: 0.31858419671654703\n",
      "iter: 9400 , loss/100it: 0.3271075415611267\n",
      "iter: 9500 , loss/100it: 0.33392293989658356\n",
      "iter: 9600 , loss/100it: 0.2994933672249317\n",
      "iter: 9700 , loss/100it: 0.3089570280909538\n",
      "iter: 9800 , loss/100it: 0.32020238116383554\n",
      "iter: 9900 , loss/100it: 0.3121467396616936\n",
      "iter: 10000 , loss/100it: 0.3129295305907726\n",
      "iter: 10000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 89 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 85 %\n",
      "iter: 10100 , loss/100it: 0.29778374239802363\n",
      "iter: 10200 , loss/100it: 0.3346232561767101\n",
      "iter: 10300 , loss/100it: 0.2957602670788765\n",
      "iter: 10400 , loss/100it: 0.30745903089642523\n",
      "iter: 10500 , loss/100it: 0.33151591926813123\n",
      "iter: 10600 , loss/100it: 0.30334436044096946\n",
      "iter: 10700 , loss/100it: 0.3095836952328682\n",
      "iter: 10800 , loss/100it: 0.30758226454257964\n",
      "iter: 10900 , loss/100it: 0.31466069966554644\n",
      "iter: 11000 , loss/100it: 0.2829743528366089\n",
      "iter: 11000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 88 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 84 %\n",
      "iter: 11100 , loss/100it: 0.300363372862339\n",
      "iter: 11200 , loss/100it: 0.30356883093714715\n",
      "iter: 11300 , loss/100it: 0.29143567591905595\n",
      "iter: 11400 , loss/100it: 0.2833575451374054\n",
      "iter: 11500 , loss/100it: 0.30943886503577234\n",
      "iter: 11600 , loss/100it: 0.29757284849882126\n",
      "iter: 11700 , loss/100it: 0.2799656938016415\n",
      "iter: 11800 , loss/100it: 0.28898332245647906\n",
      "iter: 11900 , loss/100it: 0.3033985463529825\n",
      "iter: 12000 , loss/100it: 0.2903251856565475\n",
      "iter: 12000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 89 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 84 %\n",
      "iter: 12100 , loss/100it: 0.2764809390902519\n",
      "iter: 12200 , loss/100it: 0.2902147781848907\n",
      "iter: 12300 , loss/100it: 0.2978693149983883\n",
      "iter: 12400 , loss/100it: 0.2796498829126358\n",
      "iter: 12500 , loss/100it: 0.2746133649349213\n",
      "iter: 12600 , loss/100it: 0.28896410524845123\n",
      "iter: 12700 , loss/100it: 0.2827117131650448\n",
      "iter: 12800 , loss/100it: 0.2875032512843609\n",
      "iter: 12900 , loss/100it: 0.29398621574044226\n",
      "iter: 13000 , loss/100it: 0.28989632204175\n",
      "iter: 13000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 87 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 83 %\n",
      "iter: 13100 , loss/100it: 0.2593243135511875\n",
      "iter: 13200 , loss/100it: 0.2907266141474247\n",
      "iter: 13300 , loss/100it: 0.2858354769647121\n",
      "iter: 13400 , loss/100it: 0.28271371439099313\n",
      "iter: 13500 , loss/100it: 0.2670166689157486\n",
      "iter: 13600 , loss/100it: 0.2776311057806015\n",
      "iter: 13700 , loss/100it: 0.27762901946902274\n",
      "iter: 13800 , loss/100it: 0.2721625176817179\n",
      "iter: 13900 , loss/100it: 0.2671943606436253\n",
      "iter: 14000 , loss/100it: 0.2753601039946079\n",
      "iter: 14000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 87 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 83 %\n",
      "iter: 14100 , loss/100it: 0.2716882632672787\n",
      "iter: 14200 , loss/100it: 0.27073119521141054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 14300 , loss/100it: 0.27625075027346613\n",
      "iter: 14400 , loss/100it: 0.283586850464344\n",
      "iter: 14500 , loss/100it: 0.26861775785684583\n",
      "iter: 14600 , loss/100it: 0.2724536829441786\n",
      "iter: 14700 , loss/100it: 0.2738576266169548\n",
      "iter: 14800 , loss/100it: 0.2753096230328083\n",
      "iter: 14900 , loss/100it: 0.2548686572164297\n",
      "iter: 15000 , loss/100it: 0.2657020992040634\n",
      "iter: 15000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 91 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 86 %\n",
      "iter: 15100 , loss/100it: 0.27770285099744796\n",
      "iter: 15200 , loss/100it: 0.2497419771552086\n",
      "iter: 15300 , loss/100it: 0.2548259747028351\n",
      "iter: 15400 , loss/100it: 0.26604945585131645\n",
      "iter: 15500 , loss/100it: 0.2762607631087303\n",
      "iter: 15600 , loss/100it: 0.25293921642005446\n",
      "iter: 15700 , loss/100it: 0.2580187866091728\n",
      "iter: 15800 , loss/100it: 0.2536784516274929\n",
      "iter: 15900 , loss/100it: 0.2689136382192373\n",
      "iter: 16000 , loss/100it: 0.2578543266654015\n",
      "iter: 16000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 91 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 86 %\n",
      "iter: 16100 , loss/100it: 0.2670787173509598\n",
      "iter: 16200 , loss/100it: 0.2646850633621216\n",
      "iter: 16300 , loss/100it: 0.25132681742310525\n",
      "iter: 16400 , loss/100it: 0.2482566064596176\n",
      "iter: 16500 , loss/100it: 0.27365803852677345\n",
      "iter: 16600 , loss/100it: 0.26490085661411283\n",
      "iter: 16700 , loss/100it: 0.2573424720019102\n",
      "iter: 16800 , loss/100it: 0.2584450513124466\n",
      "iter: 16900 , loss/100it: 0.26450480699539186\n",
      "iter: 17000 , loss/100it: 0.23693841457366943\n",
      "iter: 17000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 90 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 85 %\n",
      "iter: 17100 , loss/100it: 0.25873402640223503\n",
      "iter: 17200 , loss/100it: 0.25957698695361614\n",
      "iter: 17300 , loss/100it: 0.2505908066034317\n",
      "iter: 17400 , loss/100it: 0.25637650698423387\n",
      "iter: 17500 , loss/100it: 0.27812646262347696\n",
      "iter: 17600 , loss/100it: 0.25697053119540214\n",
      "iter: 17700 , loss/100it: 0.22591584779322146\n",
      "iter: 17800 , loss/100it: 0.2602599699050188\n",
      "iter: 17900 , loss/100it: 0.26724718019366267\n",
      "iter: 18000 , loss/100it: 0.25764250099658964\n",
      "iter: 18000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 90 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 86 %\n",
      "iter: 18100 , loss/100it: 0.24058705121278762\n",
      "iter: 18200 , loss/100it: 0.25546784460544586\n",
      "iter: 18300 , loss/100it: 0.25617917843163013\n",
      "iter: 18400 , loss/100it: 0.23930336780846118\n",
      "iter: 18500 , loss/100it: 0.22790617652237416\n",
      "iter: 18600 , loss/100it: 0.2540937167406082\n",
      "iter: 18700 , loss/100it: 0.2398836551606655\n",
      "iter: 18800 , loss/100it: 0.24355031803250313\n",
      "iter: 18900 , loss/100it: 0.27065323024988175\n",
      "iter: 19000 , loss/100it: 0.2552035237848759\n",
      "iter: 19000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 92 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 87 %\n",
      "iter: 19100 , loss/100it: 0.24264036670327185\n",
      "iter: 19200 , loss/100it: 0.23754959620535374\n",
      "iter: 19300 , loss/100it: 0.24431515403091908\n",
      "iter: 19400 , loss/100it: 0.2407861076295376\n",
      "iter: 19500 , loss/100it: 0.2399345748871565\n",
      "iter: 19600 , loss/100it: 0.2518470250070095\n",
      "iter: 19700 , loss/100it: 0.2612691193819046\n",
      "iter: 19800 , loss/100it: 0.23165088079869747\n",
      "iter: 19900 , loss/100it: 0.24691037580370903\n",
      "iter: 20000 , loss/100it: 0.23544276677072049\n",
      "iter: 20000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 89 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 84 %\n",
      "iter: 20100 , loss/100it: 0.2542871169745922\n",
      "iter: 20200 , loss/100it: 0.22479815058410169\n",
      "iter: 20300 , loss/100it: 0.2466313574463129\n",
      "iter: 20400 , loss/100it: 0.2691866648197174\n",
      "iter: 20500 , loss/100it: 0.2351517216861248\n",
      "iter: 20600 , loss/100it: 0.23119284510612487\n",
      "iter: 20700 , loss/100it: 0.24712130896747111\n",
      "iter: 20800 , loss/100it: 0.24101291462779045\n",
      "iter: 20900 , loss/100it: 0.24326001785695553\n",
      "iter: 21000 , loss/100it: 0.24335816748440264\n",
      "iter: 21000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 89 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 84 %\n",
      "iter: 21100 , loss/100it: 0.2499165514856577\n",
      "iter: 21200 , loss/100it: 0.2269069342315197\n",
      "iter: 21300 , loss/100it: 0.24751997731626033\n",
      "iter: 21400 , loss/100it: 0.2360258137434721\n",
      "iter: 21500 , loss/100it: 0.26152105182409285\n",
      "iter: 21600 , loss/100it: 0.22801919311285018\n",
      "iter: 21700 , loss/100it: 0.2431145065277815\n",
      "iter: 21800 , loss/100it: 0.2456899504363537\n",
      "iter: 21900 , loss/100it: 0.2292702639102936\n",
      "iter: 22000 , loss/100it: 0.23801314972341062\n",
      "iter: 22000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 87 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 83 %\n",
      "iter: 22100 , loss/100it: 0.23333104513585567\n",
      "iter: 22200 , loss/100it: 0.231456663236022\n",
      "iter: 22300 , loss/100it: 0.22250406593084335\n",
      "iter: 22400 , loss/100it: 0.23604555755853654\n",
      "iter: 22500 , loss/100it: 0.25143332600593565\n",
      "iter: 22600 , loss/100it: 0.2321197994053364\n",
      "iter: 22700 , loss/100it: 0.236175247579813\n",
      "iter: 22800 , loss/100it: 0.24881972670555114\n",
      "iter: 22900 , loss/100it: 0.23038644686341286\n",
      "iter: 23000 , loss/100it: 0.23012114994227886\n",
      "iter: 23000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 91 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 86 %\n",
      "iter: 23100 , loss/100it: 0.2290773956477642\n",
      "iter: 23200 , loss/100it: 0.24004235059022905\n",
      "iter: 23300 , loss/100it: 0.23631138138473035\n",
      "iter: 23400 , loss/100it: 0.22212978951632978\n",
      "iter: 23500 , loss/100it: 0.23528354316949845\n",
      "iter: 23600 , loss/100it: 0.2363339366018772\n",
      "iter: 23700 , loss/100it: 0.22283096179366113\n",
      "iter: 23800 , loss/100it: 0.2367098194360733\n",
      "iter: 23900 , loss/100it: 0.23015556700527667\n",
      "iter: 24000 , loss/100it: 0.23555850744247436\n",
      "iter: 24000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 85 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 80 %\n",
      "iter: 24100 , loss/100it: 0.21542809419333936\n",
      "iter: 24200 , loss/100it: 0.2376642296463251\n",
      "iter: 24300 , loss/100it: 0.24387259013950824\n",
      "iter: 24400 , loss/100it: 0.2116522665321827\n",
      "iter: 24500 , loss/100it: 0.23613090328872205\n",
      "iter: 24600 , loss/100it: 0.23047542005777358\n",
      "iter: 24700 , loss/100it: 0.21129567176103592\n",
      "iter: 24800 , loss/100it: 0.21457088112831116\n",
      "iter: 24900 , loss/100it: 0.21968094892799855\n",
      "iter: 25000 , loss/100it: 0.2462062279134989\n",
      "iter: 25000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 90 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 85 %\n",
      "iter: 25100 , loss/100it: 0.21217300795018673\n",
      "iter: 25200 , loss/100it: 0.22627648033201694\n",
      "iter: 25300 , loss/100it: 0.240832903906703\n",
      "iter: 25400 , loss/100it: 0.23151407688856124\n",
      "iter: 25500 , loss/100it: 0.22841992296278477\n",
      "iter: 25600 , loss/100it: 0.22094391725957394\n",
      "iter: 25700 , loss/100it: 0.2355976963788271\n",
      "iter: 25800 , loss/100it: 0.22780839778482914\n",
      "iter: 25900 , loss/100it: 0.23348572112619878\n",
      "iter: 26000 , loss/100it: 0.23746341869235038\n",
      "iter: 26000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 90 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 85 %\n",
      "iter: 26100 , loss/100it: 0.230827519223094\n",
      "iter: 26200 , loss/100it: 0.2260551296174526\n",
      "iter: 26300 , loss/100it: 0.2321965568512678\n",
      "iter: 26400 , loss/100it: 0.23803879059851168\n",
      "iter: 26500 , loss/100it: 0.21838179878890515\n",
      "iter: 26600 , loss/100it: 0.22109698854386806\n",
      "iter: 26700 , loss/100it: 0.22692002587020396\n",
      "iter: 26800 , loss/100it: 0.23334699928760527\n",
      "iter: 26900 , loss/100it: 0.20859212562441826\n",
      "iter: 27000 , loss/100it: 0.23654756277799607\n",
      "iter: 27000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 92 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 87 %\n",
      "iter: 27100 , loss/100it: 0.21746367730200292\n",
      "iter: 27200 , loss/100it: 0.21213808357715608\n",
      "iter: 27300 , loss/100it: 0.2292433326691389\n",
      "iter: 27400 , loss/100it: 0.22907384499907493\n",
      "iter: 27500 , loss/100it: 0.2256376599520445\n",
      "iter: 27600 , loss/100it: 0.21460720889270304\n",
      "iter: 27700 , loss/100it: 0.23895411498844624\n",
      "iter: 27800 , loss/100it: 0.2319821871072054\n",
      "iter: 27900 , loss/100it: 0.20999050304293632\n",
      "iter: 28000 , loss/100it: 0.21644845999777318\n",
      "iter: 28000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 92 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 87 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 28100 , loss/100it: 0.23251489624381066\n",
      "iter: 28200 , loss/100it: 0.21598307326436042\n",
      "iter: 28300 , loss/100it: 0.21590652890503406\n",
      "iter: 28400 , loss/100it: 0.22729399777948855\n",
      "iter: 28500 , loss/100it: 0.24062612377107143\n",
      "iter: 28600 , loss/100it: 0.20835210859775544\n",
      "iter: 28700 , loss/100it: 0.22458786115050317\n",
      "iter: 28800 , loss/100it: 0.22689737893640996\n",
      "iter: 28900 , loss/100it: 0.22786436170339586\n",
      "iter: 29000 , loss/100it: 0.20888620771467686\n",
      "iter: 29000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 90 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 85 %\n",
      "iter: 29100 , loss/100it: 0.2297537276148796\n",
      "iter: 29200 , loss/100it: 0.23325007066130637\n",
      "iter: 29300 , loss/100it: 0.2140235575288534\n",
      "iter: 29400 , loss/100it: 0.21089519873261453\n",
      "iter: 29500 , loss/100it: 0.22236458368599415\n",
      "iter: 29600 , loss/100it: 0.21225971706211566\n",
      "iter: 29700 , loss/100it: 0.21956342183053493\n",
      "iter: 29800 , loss/100it: 0.2217031627893448\n",
      "iter: 29900 , loss/100it: 0.2297920659184456\n",
      "iter: 30000 , loss/100it: 0.21452748790383339\n",
      "iter: 30000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 92 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 87 %\n",
      "iter: 30100 , loss/100it: 0.21066600151360035\n",
      "iter: 30200 , loss/100it: 0.2366098341345787\n",
      "iter: 30300 , loss/100it: 0.20879040658473969\n",
      "iter: 30400 , loss/100it: 0.2067626067996025\n",
      "iter: 30500 , loss/100it: 0.21565212428569794\n",
      "iter: 30600 , loss/100it: 0.22919473871588708\n",
      "iter: 30700 , loss/100it: 0.21517311170697212\n",
      "iter: 30800 , loss/100it: 0.20920922689139843\n",
      "iter: 30900 , loss/100it: 0.22515261188149452\n",
      "iter: 31000 , loss/100it: 0.21778339631855487\n",
      "iter: 31000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 91 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 85 %\n",
      "iter: 31100 , loss/100it: 0.2166079231351614\n",
      "iter: 31200 , loss/100it: 0.21952205069363118\n",
      "iter: 31300 , loss/100it: 0.2178476493805647\n",
      "iter: 31400 , loss/100it: 0.2047694855183363\n",
      "iter: 31500 , loss/100it: 0.20853925377130508\n",
      "iter: 31600 , loss/100it: 0.22872153170406817\n",
      "iter: 31700 , loss/100it: 0.21755798473954202\n",
      "iter: 31800 , loss/100it: 0.200655549839139\n",
      "iter: 31900 , loss/100it: 0.22059341423213483\n",
      "iter: 32000 , loss/100it: 0.22511961609125136\n",
      "iter: 32000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 91 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 86 %\n",
      "iter: 32100 , loss/100it: 0.15809814810752867\n",
      "iter: 32200 , loss/100it: 0.12599089547991751\n",
      "iter: 32300 , loss/100it: 0.11399909731000663\n",
      "iter: 32400 , loss/100it: 0.11640856958925724\n",
      "iter: 32500 , loss/100it: 0.11145867988467216\n",
      "iter: 32600 , loss/100it: 0.1062278950214386\n",
      "iter: 32700 , loss/100it: 0.09991532880812884\n",
      "iter: 32800 , loss/100it: 0.09585192043334245\n",
      "iter: 32900 , loss/100it: 0.09777024008333683\n",
      "iter: 33000 , loss/100it: 0.09406517654657363\n",
      "iter: 33000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 97 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 91 %\n",
      "iter: 33100 , loss/100it: 0.08983696222305299\n",
      "iter: 33200 , loss/100it: 0.08885527847334743\n",
      "iter: 33300 , loss/100it: 0.08664640249684454\n",
      "iter: 33400 , loss/100it: 0.09105261132121086\n",
      "iter: 33500 , loss/100it: 0.08081768719479442\n",
      "iter: 33600 , loss/100it: 0.08364286314696073\n",
      "iter: 33700 , loss/100it: 0.08123315354809164\n",
      "iter: 33800 , loss/100it: 0.07571074837818742\n",
      "iter: 33900 , loss/100it: 0.07536779614165426\n",
      "iter: 34000 , loss/100it: 0.0754629935324192\n",
      "iter: 34000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 98 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 91 %\n",
      "iter: 34100 , loss/100it: 0.0806295127607882\n",
      "iter: 34200 , loss/100it: 0.07413091694936157\n",
      "iter: 34300 , loss/100it: 0.07217583941295742\n",
      "iter: 34400 , loss/100it: 0.07900169860571622\n",
      "iter: 34500 , loss/100it: 0.07316309303045272\n",
      "iter: 34600 , loss/100it: 0.06784576933830977\n",
      "iter: 34700 , loss/100it: 0.06778394529595971\n",
      "iter: 34800 , loss/100it: 0.06988691410049797\n",
      "iter: 34900 , loss/100it: 0.07206905888393521\n",
      "iter: 35000 , loss/100it: 0.06800704900175333\n",
      "iter: 35000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 98 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 91 %\n",
      "iter: 35100 , loss/100it: 0.06432498747482895\n",
      "iter: 35200 , loss/100it: 0.06457249864935875\n",
      "iter: 35300 , loss/100it: 0.06213652750477195\n",
      "iter: 35400 , loss/100it: 0.063961460608989\n",
      "iter: 35500 , loss/100it: 0.06654354369267822\n",
      "iter: 35600 , loss/100it: 0.06151039335876703\n",
      "iter: 35700 , loss/100it: 0.0625843202881515\n",
      "iter: 35800 , loss/100it: 0.0656014615856111\n",
      "iter: 35900 , loss/100it: 0.06036725476384163\n",
      "iter: 36000 , loss/100it: 0.05817535516805947\n",
      "iter: 36000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 98 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 91 %\n",
      "iter: 36100 , loss/100it: 0.062332537891343236\n",
      "iter: 36200 , loss/100it: 0.060061986595392226\n",
      "iter: 36300 , loss/100it: 0.05868331538513303\n",
      "iter: 36400 , loss/100it: 0.054079377446323636\n",
      "iter: 36500 , loss/100it: 0.05670802304521203\n",
      "iter: 36600 , loss/100it: 0.060702766161412\n",
      "iter: 36700 , loss/100it: 0.058135717138648034\n",
      "iter: 36800 , loss/100it: 0.05726474476978183\n",
      "iter: 36900 , loss/100it: 0.05471486499533057\n",
      "iter: 37000 , loss/100it: 0.05693999918177724\n",
      "iter: 37000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 98 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 91 %\n",
      "iter: 37100 , loss/100it: 0.05461808508262038\n",
      "iter: 37200 , loss/100it: 0.057926062848418954\n",
      "iter: 37300 , loss/100it: 0.055362484119832515\n",
      "iter: 37400 , loss/100it: 0.05377732466906309\n",
      "iter: 37500 , loss/100it: 0.04996879897080362\n",
      "iter: 37600 , loss/100it: 0.05160560393705964\n",
      "iter: 37700 , loss/100it: 0.04872740920633078\n",
      "iter: 37800 , loss/100it: 0.04920603711158037\n",
      "iter: 37900 , loss/100it: 0.05334192743524909\n",
      "iter: 38000 , loss/100it: 0.05165357992984355\n",
      "iter: 38000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 98 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 91 %\n",
      "iter: 38100 , loss/100it: 0.050038018245249984\n",
      "iter: 38200 , loss/100it: 0.05270163181237877\n",
      "iter: 38300 , loss/100it: 0.05200653358362615\n",
      "iter: 38400 , loss/100it: 0.04841244654729962\n",
      "iter: 38500 , loss/100it: 0.05336508503183723\n",
      "iter: 38600 , loss/100it: 0.047488278420642016\n",
      "iter: 38700 , loss/100it: 0.05136158379726112\n",
      "iter: 38800 , loss/100it: 0.04537649564445019\n",
      "iter: 38900 , loss/100it: 0.046394642619416115\n",
      "iter: 39000 , loss/100it: 0.0485239571519196\n",
      "iter: 39000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 98 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 91 %\n",
      "iter: 39100 , loss/100it: 0.044419751977548\n",
      "iter: 39200 , loss/100it: 0.04914585300721228\n",
      "iter: 39300 , loss/100it: 0.0459122577495873\n",
      "iter: 39400 , loss/100it: 0.04878057254478335\n",
      "iter: 39500 , loss/100it: 0.04417075797915459\n",
      "iter: 39600 , loss/100it: 0.04762221661396324\n",
      "iter: 39700 , loss/100it: 0.0452032517362386\n",
      "iter: 39800 , loss/100it: 0.04482783107087016\n",
      "iter: 39900 , loss/100it: 0.041122014997527004\n",
      "iter: 40000 , loss/100it: 0.044828314101323485\n",
      "iter: 40000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 99 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 91 %\n",
      "iter: 40100 , loss/100it: 0.046475001834332945\n",
      "iter: 40200 , loss/100it: 0.04151587384752929\n",
      "iter: 40300 , loss/100it: 0.04235426078550517\n",
      "iter: 40400 , loss/100it: 0.04148168700747192\n",
      "iter: 40500 , loss/100it: 0.0428675648663193\n",
      "iter: 40600 , loss/100it: 0.04320233900099993\n",
      "iter: 40700 , loss/100it: 0.04286347459536046\n",
      "iter: 40800 , loss/100it: 0.04683689022436738\n",
      "iter: 40900 , loss/100it: 0.039893545163795355\n",
      "iter: 41000 , loss/100it: 0.03747203066945076\n",
      "iter: 41000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 99 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 91 %\n",
      "iter: 41100 , loss/100it: 0.037137560015544295\n",
      "iter: 41200 , loss/100it: 0.03893596427515149\n",
      "iter: 41300 , loss/100it: 0.03996630672365427\n",
      "iter: 41400 , loss/100it: 0.03923036367632449\n",
      "iter: 41500 , loss/100it: 0.03900564641691744\n",
      "iter: 41600 , loss/100it: 0.042144948169589046\n",
      "iter: 41700 , loss/100it: 0.03797953986562788\n",
      "iter: 41800 , loss/100it: 0.04164102380163968\n",
      "iter: 41900 , loss/100it: 0.042313823951408265\n",
      "iter: 42000 , loss/100it: 0.03961164930835366\n",
      "iter: 42000 , test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 99 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 91 %\n",
      "iter: 42100 , loss/100it: 0.0399103246582672\n",
      "iter: 42200 , loss/100it: 0.03846651874948293\n",
      "iter: 42300 , loss/100it: 0.0424110515974462\n",
      "iter: 42400 , loss/100it: 0.04098502713721246\n",
      "iter: 42500 , loss/100it: 0.03750155781395734\n",
      "iter: 42600 , loss/100it: 0.039600168988108635\n",
      "iter: 42700 , loss/100it: 0.03578881136141718\n",
      "iter: 42800 , loss/100it: 0.04131331570446491\n",
      "iter: 42900 , loss/100it: 0.03558808712288737\n",
      "iter: 43000 , loss/100it: 0.03976568982936442\n",
      "iter: 43000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 99 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 91 %\n",
      "iter: 43100 , loss/100it: 0.03506295224651694\n",
      "iter: 43200 , loss/100it: 0.032540793465450406\n",
      "iter: 43300 , loss/100it: 0.03529857345391065\n",
      "iter: 43400 , loss/100it: 0.03633990404196084\n",
      "iter: 43500 , loss/100it: 0.032164681483991445\n",
      "iter: 43600 , loss/100it: 0.03817823780700565\n",
      "iter: 43700 , loss/100it: 0.03592523648403585\n",
      "iter: 43800 , loss/100it: 0.03327649241313338\n",
      "iter: 43900 , loss/100it: 0.040409674430266024\n",
      "iter: 44000 , loss/100it: 0.03597765114624053\n",
      "iter: 44000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 99 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 91 %\n",
      "iter: 44100 , loss/100it: 0.0321314756013453\n",
      "iter: 44200 , loss/100it: 0.03699018098413944\n",
      "iter: 44300 , loss/100it: 0.03423473376780748\n",
      "iter: 44400 , loss/100it: 0.036206773263402284\n",
      "iter: 44500 , loss/100it: 0.031615197136998174\n",
      "iter: 44600 , loss/100it: 0.03787821358535439\n",
      "iter: 44700 , loss/100it: 0.036502351155504584\n",
      "iter: 44800 , loss/100it: 0.03220726707950235\n",
      "iter: 44900 , loss/100it: 0.03407996737398207\n",
      "iter: 45000 , loss/100it: 0.03790607871487737\n",
      "iter: 45000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 99 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 91 %\n",
      "iter: 45100 , loss/100it: 0.034695911211892964\n",
      "iter: 45200 , loss/100it: 0.03452412458602339\n",
      "iter: 45300 , loss/100it: 0.03212536012288183\n",
      "iter: 45400 , loss/100it: 0.03419307313393802\n",
      "iter: 45500 , loss/100it: 0.03484197648242116\n",
      "iter: 45600 , loss/100it: 0.03167510217987001\n",
      "iter: 45700 , loss/100it: 0.03192527484614402\n",
      "iter: 45800 , loss/100it: 0.033071093866601585\n",
      "iter: 45900 , loss/100it: 0.031279436596669256\n",
      "iter: 46000 , loss/100it: 0.031502932370640335\n",
      "iter: 46000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 99 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 91 %\n",
      "iter: 46100 , loss/100it: 0.035007463339716195\n",
      "iter: 46200 , loss/100it: 0.03371721846051514\n",
      "iter: 46300 , loss/100it: 0.030306552723050117\n",
      "iter: 46400 , loss/100it: 0.03286060470622033\n",
      "iter: 46500 , loss/100it: 0.03139751611277461\n",
      "iter: 46600 , loss/100it: 0.03244421043433249\n",
      "iter: 46700 , loss/100it: 0.034029092949349436\n",
      "iter: 46800 , loss/100it: 0.030092654074542223\n",
      "iter: 46900 , loss/100it: 0.029757942664436998\n",
      "iter: 47000 , loss/100it: 0.03160238794051111\n",
      "iter: 47000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 99 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 91 %\n",
      "iter: 47100 , loss/100it: 0.02972740402445197\n",
      "iter: 47200 , loss/100it: 0.02669759554322809\n",
      "iter: 47300 , loss/100it: 0.029479170190170406\n",
      "iter: 47400 , loss/100it: 0.02951820203103125\n",
      "iter: 47500 , loss/100it: 0.03004965259693563\n",
      "iter: 47600 , loss/100it: 0.02743410687893629\n",
      "iter: 47700 , loss/100it: 0.028607542735990137\n",
      "iter: 47800 , loss/100it: 0.030620084309484808\n",
      "iter: 47900 , loss/100it: 0.03005422245245427\n",
      "iter: 48000 , loss/100it: 0.029519715304486452\n",
      "iter: 48000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 99 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 91 %\n",
      "iter: 48100 , loss/100it: 0.02849920128006488\n",
      "iter: 48200 , loss/100it: 0.027650500795571135\n",
      "iter: 48300 , loss/100it: 0.025259875485207885\n",
      "iter: 48400 , loss/100it: 0.024691934660077096\n",
      "iter: 48500 , loss/100it: 0.02375720946583897\n",
      "iter: 48600 , loss/100it: 0.022732712326105683\n",
      "iter: 48700 , loss/100it: 0.022511416808702053\n",
      "iter: 48800 , loss/100it: 0.025626393598504365\n",
      "iter: 48900 , loss/100it: 0.025745896943844854\n",
      "iter: 49000 , loss/100it: 0.0222326596500352\n",
      "iter: 49000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 99 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 91 %\n",
      "iter: 49100 , loss/100it: 0.025268891132436692\n",
      "iter: 49200 , loss/100it: 0.021589656108990312\n",
      "iter: 49300 , loss/100it: 0.024066655267961323\n",
      "iter: 49400 , loss/100it: 0.023384421016089618\n",
      "iter: 49500 , loss/100it: 0.021385308559983968\n",
      "iter: 49600 , loss/100it: 0.02142032765550539\n",
      "iter: 49700 , loss/100it: 0.02369372221175581\n",
      "iter: 49800 , loss/100it: 0.023617247010115534\n",
      "iter: 49900 , loss/100it: 0.02171295799780637\n",
      "iter: 50000 , loss/100it: 0.021737488987855613\n",
      "iter: 50000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 99 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 91 %\n",
      "iter: 50100 , loss/100it: 0.02267938297241926\n",
      "iter: 50200 , loss/100it: 0.02349214754998684\n",
      "iter: 50300 , loss/100it: 0.023233270449563862\n",
      "iter: 50400 , loss/100it: 0.021079273100476713\n",
      "iter: 50500 , loss/100it: 0.024397874581627548\n",
      "iter: 50600 , loss/100it: 0.023312156526371836\n",
      "iter: 50700 , loss/100it: 0.023480675099417567\n",
      "iter: 50800 , loss/100it: 0.021378885556478055\n",
      "iter: 50900 , loss/100it: 0.022812607381492853\n",
      "iter: 51000 , loss/100it: 0.02406871301587671\n",
      "iter: 51000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 99 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 91 %\n",
      "iter: 51100 , loss/100it: 0.020461406796239315\n",
      "iter: 51200 , loss/100it: 0.021740551728289575\n",
      "iter: 51300 , loss/100it: 0.02125892444048077\n",
      "iter: 51400 , loss/100it: 0.022826664936728774\n",
      "iter: 51500 , loss/100it: 0.02060829539783299\n",
      "iter: 51600 , loss/100it: 0.020921636892016978\n",
      "iter: 51700 , loss/100it: 0.0228487055352889\n",
      "iter: 51800 , loss/100it: 0.02140103923622519\n",
      "iter: 51900 , loss/100it: 0.024226480438373985\n",
      "iter: 52000 , loss/100it: 0.021294419490732252\n",
      "iter: 52000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 99 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 91 %\n",
      "iter: 52100 , loss/100it: 0.02015418006107211\n",
      "iter: 52200 , loss/100it: 0.02044842636445537\n",
      "iter: 52300 , loss/100it: 0.019641752776224167\n",
      "iter: 52400 , loss/100it: 0.02438214091118425\n",
      "iter: 52500 , loss/100it: 0.019958894751034677\n",
      "iter: 52600 , loss/100it: 0.020394502384588124\n",
      "iter: 52700 , loss/100it: 0.021561640561558307\n",
      "iter: 52800 , loss/100it: 0.019710267768241464\n",
      "iter: 52900 , loss/100it: 0.020661735569592565\n",
      "iter: 53000 , loss/100it: 0.023057167392689735\n",
      "iter: 53000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 99 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 91 %\n",
      "iter: 53100 , loss/100it: 0.02031157972291112\n",
      "iter: 53200 , loss/100it: 0.019301204378716647\n",
      "iter: 53300 , loss/100it: 0.0199488173564896\n",
      "iter: 53400 , loss/100it: 0.02117680269526318\n",
      "iter: 53500 , loss/100it: 0.021619511754252016\n",
      "iter: 53600 , loss/100it: 0.020591429714113475\n",
      "iter: 53700 , loss/100it: 0.021561336917802692\n",
      "iter: 53800 , loss/100it: 0.02345874549821019\n",
      "iter: 53900 , loss/100it: 0.019342855111462994\n",
      "iter: 54000 , loss/100it: 0.02078843688359484\n",
      "iter: 54000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 99 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 91 %\n",
      "iter: 54100 , loss/100it: 0.02173788959858939\n",
      "iter: 54200 , loss/100it: 0.0184376923693344\n",
      "iter: 54300 , loss/100it: 0.01941854406846687\n",
      "iter: 54400 , loss/100it: 0.022094975295476615\n",
      "iter: 54500 , loss/100it: 0.020351564092561603\n",
      "iter: 54600 , loss/100it: 0.02165392915951088\n",
      "iter: 54700 , loss/100it: 0.019855815754272043\n",
      "iter: 54800 , loss/100it: 0.020100272018462418\n",
      "iter: 54900 , loss/100it: 0.020195129385683686\n",
      "iter: 55000 , loss/100it: 0.019046598540153354\n",
      "iter: 55000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 99 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 92 %\n",
      "iter: 55100 , loss/100it: 0.02200571273919195\n",
      "iter: 55200 , loss/100it: 0.02077040312346071\n",
      "iter: 55300 , loss/100it: 0.017443451434373855\n",
      "iter: 55400 , loss/100it: 0.01886931504588574\n",
      "iter: 55500 , loss/100it: 0.02249079870060086\n",
      "iter: 55600 , loss/100it: 0.018731758082285523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 55700 , loss/100it: 0.020612470677588136\n",
      "iter: 55800 , loss/100it: 0.021666760239750147\n",
      "iter: 55900 , loss/100it: 0.01862028471659869\n",
      "iter: 56000 , loss/100it: 0.020962173724547027\n",
      "iter: 56000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 99 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 91 %\n",
      "iter: 56100 , loss/100it: 0.020784774208441378\n",
      "iter: 56200 , loss/100it: 0.01843850968987681\n",
      "iter: 56300 , loss/100it: 0.021061465851962568\n",
      "iter: 56400 , loss/100it: 0.022172010163776578\n",
      "iter: 56500 , loss/100it: 0.02111601174576208\n",
      "iter: 56600 , loss/100it: 0.018930547547060996\n",
      "iter: 56700 , loss/100it: 0.01884787459857762\n",
      "iter: 56800 , loss/100it: 0.01955086597474292\n",
      "iter: 56900 , loss/100it: 0.01926923110615462\n",
      "iter: 57000 , loss/100it: 0.02012533846544102\n",
      "iter: 57000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 99 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 92 %\n",
      "iter: 57100 , loss/100it: 0.021056120458524674\n",
      "iter: 57200 , loss/100it: 0.021722556129097938\n",
      "iter: 57300 , loss/100it: 0.01981618439545855\n",
      "iter: 57400 , loss/100it: 0.01942573861218989\n",
      "iter: 57500 , loss/100it: 0.019995766275096683\n",
      "iter: 57600 , loss/100it: 0.01808382250368595\n",
      "iter: 57700 , loss/100it: 0.019732860648073256\n",
      "iter: 57800 , loss/100it: 0.019389089301694185\n",
      "iter: 57900 , loss/100it: 0.019913406083360313\n",
      "iter: 58000 , loss/100it: 0.01988157601095736\n",
      "iter: 58000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 99 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 91 %\n",
      "iter: 58100 , loss/100it: 0.020067591592669486\n",
      "iter: 58200 , loss/100it: 0.020309196093585342\n",
      "iter: 58300 , loss/100it: 0.01968408854212612\n",
      "iter: 58400 , loss/100it: 0.019056764421984552\n",
      "iter: 58500 , loss/100it: 0.0208845788333565\n",
      "iter: 58600 , loss/100it: 0.022156938079278918\n",
      "iter: 58700 , loss/100it: 0.018287351825274526\n",
      "iter: 58800 , loss/100it: 0.020501177972182632\n",
      "iter: 58900 , loss/100it: 0.01822939599864185\n",
      "iter: 59000 , loss/100it: 0.019815526590682565\n",
      "iter: 59000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 99 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 92 %\n",
      "iter: 59100 , loss/100it: 0.021084266286343335\n",
      "iter: 59200 , loss/100it: 0.01945419459603727\n",
      "iter: 59300 , loss/100it: 0.02012792238034308\n",
      "iter: 59400 , loss/100it: 0.02097992177121341\n",
      "iter: 59500 , loss/100it: 0.01688857894856483\n",
      "iter: 59600 , loss/100it: 0.018044020768720657\n",
      "iter: 59700 , loss/100it: 0.01769414996728301\n",
      "iter: 59800 , loss/100it: 0.017908510942943393\n",
      "iter: 59900 , loss/100it: 0.01813279316527769\n",
      "iter: 60000 , loss/100it: 0.0190605464624241\n",
      "iter: 60000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 99 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 91 %\n",
      "iter: 60100 , loss/100it: 0.018307520949747413\n",
      "iter: 60200 , loss/100it: 0.020212159529328345\n",
      "iter: 60300 , loss/100it: 0.017108493442647157\n",
      "iter: 60400 , loss/100it: 0.019353365474380553\n",
      "iter: 60500 , loss/100it: 0.021804373997729273\n",
      "iter: 60600 , loss/100it: 0.01886202678550035\n",
      "iter: 60700 , loss/100it: 0.01748562836786732\n",
      "iter: 60800 , loss/100it: 0.018568919445388018\n",
      "iter: 60900 , loss/100it: 0.019580553704872727\n",
      "iter: 61000 , loss/100it: 0.017560596861876547\n",
      "iter: 61000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 99 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 92 %\n",
      "iter: 61100 , loss/100it: 0.017570185977965593\n",
      "iter: 61200 , loss/100it: 0.017725258758291604\n",
      "iter: 61300 , loss/100it: 0.019279607241041958\n",
      "iter: 61400 , loss/100it: 0.018553457276429982\n",
      "iter: 61500 , loss/100it: 0.019201536496402695\n",
      "iter: 61600 , loss/100it: 0.019137904194649308\n",
      "iter: 61700 , loss/100it: 0.020051719227340073\n",
      "iter: 61800 , loss/100it: 0.018855261511635035\n",
      "iter: 61900 , loss/100it: 0.019114510633517056\n",
      "iter: 62000 , loss/100it: 0.018793174840975552\n",
      "iter: 62000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 99 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 92 %\n",
      "iter: 62100 , loss/100it: 0.02026886338600889\n",
      "iter: 62200 , loss/100it: 0.017456822553649543\n",
      "iter: 62300 , loss/100it: 0.01933218303602189\n",
      "iter: 62400 , loss/100it: 0.016390044325962663\n",
      "iter: 62500 , loss/100it: 0.01625707119004801\n",
      "iter: 62600 , loss/100it: 0.018280650302767754\n",
      "iter: 62700 , loss/100it: 0.01679110911441967\n",
      "iter: 62800 , loss/100it: 0.01831071065738797\n",
      "iter: 62900 , loss/100it: 0.01762438592966646\n",
      "iter: 63000 , loss/100it: 0.0198793887719512\n",
      "iter: 63000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 99 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 92 %\n",
      "iter: 63100 , loss/100it: 0.019034700589254498\n",
      "iter: 63200 , loss/100it: 0.017323647129815073\n",
      "iter: 63300 , loss/100it: 0.01806092930259183\n",
      "iter: 63400 , loss/100it: 0.016472576309461147\n",
      "iter: 63500 , loss/100it: 0.01817877235589549\n",
      "iter: 63600 , loss/100it: 0.02032097986899316\n",
      "iter: 63700 , loss/100it: 0.016478936386993156\n",
      "iter: 63800 , loss/100it: 0.019572812672704457\n",
      "iter: 63900 , loss/100it: 0.019805861685890703\n",
      "iter: 64000 , loss/100it: 0.017664578661788256\n",
      "iter: 64000 , test\n",
      "0 / 352\n",
      "100 / 352\n",
      "200 / 352\n",
      "300 / 352\n",
      "Accuracy on training images: 99 %\n",
      "0 / 79\n",
      "50 / 79\n",
      "Accuracy on test images: 92 %\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter()\n",
    "running_loss = 0.0\n",
    "net.train();\n",
    "while(it<=end_iter):\n",
    "    for data in trainloader:\n",
    "        it+=1\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        \n",
    "        #random flip, constant padding, random crop\n",
    "        if np.random.randint(0,2) == 0:\n",
    "            inputs = torch.flip(inputs, [3])\n",
    "        inputs = F.pad(inputs, (4, 4, 4, 4))\n",
    "        W = inputs.size()[2]\n",
    "        H = inputs.size()[3] \n",
    "        Ws = np.random.randint(0, W-32, 1)[0]\n",
    "        Hs = np.random.randint(0, H-32, 1)[0]\n",
    "        inputs = inputs[:,:,Ws:Ws+32,Hs:Hs+32]\n",
    "        \n",
    "        #training\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if it == 32000 or it == 48000:\n",
    "            scheduler.step()\n",
    "            PATH = './cifar_10_resnet'+str(N*6+2)+'_iter'+str(it)+'.pth'\n",
    "            torch.save(net.state_dict(), PATH)\n",
    "            \n",
    "        running_loss += loss.item()\n",
    "        if it % 100 == 0:\n",
    "            print(\"iter:\",it,\", loss/100it:\",running_loss / 100)\n",
    "            writer.add_scalar('training loss', running_loss / 100,it)\n",
    "            running_loss = 0.0\n",
    "            \n",
    "        if it % 1000 == 0:\n",
    "            print(\"iter:\",it,\", test\")\n",
    "            net.eval();\n",
    "            #for Training set\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            with torch.no_grad():\n",
    "                for i,data in enumerate(trainloader):\n",
    "                    if i % 100 == 0:\n",
    "                        print(i,\"/\",len(trainloader))\n",
    "                    inputs, labels = data[0].to(device), data[1].to(device)\n",
    "                    \n",
    "                    outputs = net(inputs)\n",
    "\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "            print('Accuracy on training images: %d %%' % (100 * correct / total))\n",
    "            writer.add_scalar('Acc on training', (100 * correct / total),it)\n",
    "            \n",
    "            #for Test set\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            with torch.no_grad():\n",
    "                for i,data in enumerate(testloader):\n",
    "                    if i % 50 == 0:\n",
    "                        print(i,\"/\",len(testloader))\n",
    "                    inputs, labels = data[0].to(device), data[1].to(device)\n",
    "                    \n",
    "                    outputs = net(inputs)\n",
    "\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "            print('Accuracy on test images: %d %%' % (100 * correct / total))\n",
    "            writer.add_scalar('Acc on testing', (100 * correct / total),it)\n",
    "            net.train();\n",
    "        \n",
    "print('Finished Training')\n",
    "\n",
    "PATH = './cifar_10_resnet'+str(N*6+2)+'_iter'+str(it)+'.pth'\n",
    "torch.save(net.state_dict(), PATH)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "eclee_pt",
   "language": "python",
   "name": "eclee_pt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
